{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c29c9ff-5273-4bd1-9952-b1ef8a7c8d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp data_provider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82658e0-1f45-4e64-9b6e-9090f8508fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from fastcore.foundation import patch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8955535-3f82-4a44-bd5e-1588c7338cfd",
   "metadata": {},
   "source": [
    "# Data Provider\n",
    "\n",
    "> This module is responsible for processing raw TRR data for further analysis. ToDo: This code should be formatted as a class that gets the data folder path on init."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ae00df-b3fa-42f0-b47c-8f952c9dd5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class DataProvider():\n",
    "    def __init__(self, data_folder_path):\n",
    "        self.data_folder_path = data_folder_path\n",
    "        self.raw = os.path.join(data_folder_path, 'raw')\n",
    "        self.external = os.path.join(data_folder_path, 'external')\n",
    "        self.interim = os.path.join(data_folder_path, 'interim')\n",
    "        self.processed = os.path.join(data_folder_path, 'processed')\n",
    "        # Checking if folder paths exist\n",
    "        assert os.path.isdir(self.external), \"External data folder not found.\"\n",
    "        assert os.path.isdir(self.raw), \"Raw data folder not found.\"\n",
    "        assert os.path.isdir(self.interim), \"Interim data folder not found.\"\n",
    "        assert os.path.isdir(self.processed), \"Processed data folder not found.\"\n",
    "        self.phonescreening_data_path = os.path.join(self.raw, \"phonescreening.csv\")\n",
    "        self.phone_codebook_path = os.path.join(self.external, \"phone_codebook.html\")\n",
    "        self.ba_codebook_path = os.path.join(self.external, \"ba_codebook.html\")\n",
    "        self.ba_data_path = os.path.join(self.raw, \"ba.csv\")\n",
    "        self.b07_participants_path = os.path.join(self.external, \"b7_participants.xlsx\")\n",
    "\n",
    "        \n",
    "#export\n",
    "def get_efficiently(func):\n",
    "    \"\"\"\n",
    "    This decorator wraps around functions that get data and handles data storage.\n",
    "    If the output from the function hasn't been stored yet, it stores it in \"[path_to_interim]/[function_name_without_get].parquet\"\n",
    "    If the output from the function has been stored already, it loads the stored file instead of running the function (unless update is specified as True)\n",
    "    \"\"\"\n",
    "    def w(*args, update = False, columns = None, path = None, **kw):\n",
    "        _self = args[0] # Getting self to grab interim path from DataProvider\n",
    "        var_name = func.__name__.replace('get_','')\n",
    "        file_path = os.path.join(_self.interim, \"%s.parquet\"%var_name)\n",
    "        if os.path.exists(file_path) and (update == False):\n",
    "            result =  pd.read_parquet(file_path, columns = columns)\n",
    "        else:\n",
    "            print(\"Preparing %s\"%var_name)\n",
    "            result = func(_self)\n",
    "            result.to_parquet(file_path)\n",
    "        return result\n",
    "    w.__wrapped__ = func # Specifying the wrapped function for inspection\n",
    "    w.__doc__ = func.__doc__\n",
    "    w.__name__ = func.__name__\n",
    "    w.__annotations__ = {'cls':DataProvider, 'as_prop':False} # Adding parameters to make this work with @patch\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ebd203-05ed-4da7-9a78-20f0bc31f21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dp = DataProvider('/Users/hilmarzech/Projects/trr265/trr265/data/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada8fe42-eee8-4938-b729-897c1d50412e",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bbd6bf-0a55-4111-b8d4-d352acbb9c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def store_interim(self:DataProvider, df, filename):\n",
    "    path = os.path.join(self.interim,\"%s.parquet\"%filename)\n",
    "    df.to_parquet(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5865e3c8-7327-4474-8ed7-e3588c748e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def load_interim(self:DataProvider, filename):\n",
    "    return pd.read_parquet(os.path.join(self.interim,\"%s.parquet\"%filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e27e5e-a062-4a4b-a328-9e28cbcf4b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def storing_test(dp):\n",
    "    df = pd.DataFrame({\"test\":[4]})\n",
    "    # Storing the dataframe\n",
    "    dp.store_interim(df, 'storing_test')\n",
    "    # Reloading it and comparing to original\n",
    "    return df.equals(dp.load_interim('storing_test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afba6ab-375c-4c7c-ba6a-daeb4d82085c",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert storing_test(dp), \"Data storage is failing.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba56b438-5e7e-48e8-9b5b-1f034d5f094b",
   "metadata": {},
   "source": [
    "### Getting phone screening data\n",
    "> This functions get the phone screening data from redcap.  To run them, first go to redcap and download the phonescreening data to 'raw/phonescreening.csv' and the phonescreening codebook to 'external/phone_codebook.html'.  You also need the external/b7_participants.xlsx (if it's not in the cloned package, ask Hilmar for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e006e1c2-3323-493a-824f-8f0c41933ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "@get_efficiently\n",
    "def get_phone_codebook(self:DataProvider):\n",
    "    tables = pd.read_html(open(self.phone_codebook_path,'r').read())\n",
    "    df = tables[1]\n",
    "    # Note that str.contains fills NaN values with nan, which can lead to strange results during filtering\n",
    "    df = df[df.LabelHinweistext.str.contains('Fragebogen:',na=False)==False]\n",
    "    df = df.set_index('#')\n",
    "    # Parsing variable name\n",
    "    df['variable'] = df[\"Variable / Feldname\"].apply(lambda x: x.split(' ')[0])\n",
    "    # Parsing condition under which variable is displayed\n",
    "    df['condition'] = df[\"Variable / Feldname\"].apply(lambda x: ' '.join(x.split(' ')[1:]).strip() if len(x.split(' '))>1 else '')\n",
    "    df['condition'] = df.condition.apply(lambda x: x.replace('Zeige das Feld nur wenn:  ',''))\n",
    "    # Parsing labels for numerical data\n",
    "    df['labels'] = np.nan\n",
    "    labels = tables[2:-1]\n",
    "    try:\n",
    "        labels = [dict(zip(l[0],l[1])) for l in labels]\n",
    "    except:\n",
    "        display(table)\n",
    "    searchfor = [\"radio\",\"dropdown\",\"yesno\",\"checkbox\"]\n",
    "    with_table = df['Feld Attribute (Feld-Typ, Prüfung, Auswahlen, Verzweigungslogik, Berechnungen, usw.)'].str.contains('|'.join(searchfor))\n",
    "    df.loc[with_table,'labels'] = labels\n",
    "    df = df.astype(str)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66da2adf-b8cb-4406-8432-c014118de059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing phone_codebook\n"
     ]
    }
   ],
   "source": [
    "assert 'participant_id' in dp.get_phone_codebook(update = True).variable.values, \"Failed to load phone_codebook.html\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560ed51b-7c8d-4cc3-9244-6288ebe436c1",
   "metadata": {},
   "source": [
    "> Initially, participants from b07 were stored in the same RedCap project as S01 participants.  This function attempts to disentangle the two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e61704b-bde0-4082-8ca7-5d1025a43180",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "@patch\n",
    "def determine_phone_b07(self:DataProvider, df):\n",
    "    # Some initial fixes\n",
    "    df.loc[df.center=='d','screen_caller'] = df.loc[df.center=='d','screen_caller'].str.lower().str.strip().replace('leo','leonard visser').replace('sebastian mörcke','sebastian möricke').replace('jessica zimmerman','jessica zimmermann').replace('miriam-sophie petasch','miriam petasch').replace('dorothee','dorothee scheuermann')\n",
    "    # Cleaning screener list\n",
    "    dd_screeners = df[(df.center=='d')&(df.screen_caller.isna()==False)].screen_caller.unique()\n",
    "    def clean_screeners(dd_screeners):\n",
    "        dd_screeners = [y  for x in dd_screeners for y in x.split('+')]\n",
    "        dd_screeners = [y  for x in dd_screeners for y in x.split(',')]\n",
    "        dd_screeners = [y  for x in dd_screeners for y in x.split('und')]\n",
    "        dd_screeners = [y.replace('(15.02.21)','')  for x in dd_screeners for y in x.split('/')]\n",
    "        dd_screeners = [y.replace(')','').strip().lower()  for x in dd_screeners for y in x.split('(')]\n",
    "        dd_screeners = sorted(list(set(dd_screeners)))\n",
    "        return dd_screeners\n",
    "    dd_screeners = clean_screeners(dd_screeners)\n",
    "    \n",
    "    b07_screeners = ['ann-kathrin stock','charlotte blum','josephine kirschgens','klara macht','borchardt','marta ledro','miriam petasch','mona hofmann','theo tester']\n",
    "    s01_screeners = ['esther preuschhof', 'miriam schmitz', 'sebastian möricke', 'jessica zimmermann', 'leonard visser', 'anna-lena lünert', 'anne dörfler', 'dominic reichert', 'maike borchardt', 'dorothee scheuermann', 'paula böhlmann', 'alice']\n",
    "    known_dd_screeners = list(b07_screeners+s01_screeners)\n",
    "    dd_screeners = df[(df.center=='d')&(df.screen_caller.isna()==False)].screen_caller.unique()\n",
    "    # Checking if all Dresden phone screeners are accounted for\n",
    "    assert df[(df.center=='d')&(df.screen_caller)].screen_caller.str.contains('|'.join(known_dd_screeners)).mean()==1, \"Unknown Dresden phone screener: %s\"%', '.join(set(clean_screeners(dd_screeners))-set(known_dd_screeners))\n",
    "    # In general, if a screener from a project was involved, it was screened for that project\n",
    "    df['screened_for_b07'] = (df.center=='d') & (df.screen_caller.str.contains('|'.join(b07_screeners)))\n",
    "    df['screened_for_s01'] = (df.center!='d') | (df.screen_caller.str.contains('|'.join(s01_screeners)))\n",
    "    \n",
    "    # We also exclude participants screened for C02 in Berlin\n",
    "    df.loc[(df.screen_purpose == 4) & (df.center=='b'), 'screened_for_s01'] = False\n",
    "    \n",
    "    # Additionally, we also set it to true if it was specifically set\n",
    "    df.loc[df.screen_site_dd == 1, 'screened_for_s01'] = True\n",
    "    df.loc[df.screen_site_dd == 3, 'screened_for_s01'] = True\n",
    "    df.loc[df.screen_site_dd == 2, 'screened_for_b07'] = True\n",
    "    df.loc[df.screen_site_dd == 3, 'screened_for_b07'] = True\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f792bc63-1988-43ea-9e6d-36297a98679d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def check_participant_id(self:DataProvider,x):\n",
    "    '''This function checks whether a participant ID is numerical and lower than 20000.'''\n",
    "    if str(x) == x:\n",
    "        if x.isnumeric():\n",
    "            x = float(x)\n",
    "        else:\n",
    "            return False\n",
    "    if x > 20000:\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e10dd6b-d759-4a74-8f35-a214614917cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def test_check_participant_id(self:DataProvider):\n",
    "    failed = dp.check_participant_id('test10') == False # Example of a bad participant ID\n",
    "    passed = dp.check_participant_id('100') == True # Example of a good participant ID\n",
    "    return failed and passed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f904a93-8d56-4f33-9214-5468b64a0fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert dp.test_check_participant_id(), \"Participant ID check is not working\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9fd271-7607-46d6-aa38-6947203fe60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def set_dtypes(self:DataProvider, data, codebook):\n",
    "    '''This function automatically adjust data types of redcap data based on the redcap codebooks'''\n",
    "    # Parsing type\n",
    "    codebook['type'] = codebook[\"Feld Attribute (Feld-Typ, Prüfung, Auswahlen, Verzweigungslogik, Berechnungen, usw.)\"].apply(lambda x: x.split(',')[0]) \n",
    "    # Descriptives (not in data)\n",
    "    desc_columns = list(codebook[codebook.type.str.contains('descriptive')].variable)\n",
    "    # Datetime\n",
    "    dt_columns = codebook[(codebook.type.isin(['text (datetime_dmy)','text (date_dmy)']))].variable\n",
    "    dt_columns = list(set(data.columns).intersection(dt_columns))\n",
    "    # Numerical\n",
    "    num_columns = []\n",
    "    num_columns += list(codebook[codebook.type.str.contains('calc')].variable)\n",
    "    num_columns += list(codebook[codebook.type.str.contains('checkbox')].variable)\n",
    "    num_columns += list(codebook[codebook.type.str.contains('radio')].variable)\n",
    "    num_columns += list(codebook[codebook.type.str.contains('text \\(number')].variable)\n",
    "    num_columns += list(codebook[codebook.type.str.contains('yesno')].variable)\n",
    "    num_columns += list(codebook[codebook.type.str.contains('dropdown')].variable)\n",
    "    num_columns += list(codebook[codebook.type.str.contains('slider')].variable)\n",
    "    num_columns = list(set(data.columns).intersection(num_columns))\n",
    "    # Text\n",
    "    text_columns = []\n",
    "    text_columns += list(codebook[(codebook.type.str.contains('text')) & (~codebook.type.str.contains('date_dmy|datetime_dmy'))].variable)\n",
    "    text_columns += list(codebook[(codebook.type.str.contains('notes'))].variable)\n",
    "    text_columns += list(codebook[(codebook.type.str.contains('file'))].variable)\n",
    "    text_columns = list(set(data.columns).intersection(text_columns))\n",
    "    assert len(set(num_columns).intersection(set(dt_columns)))==0, set(num_columns).intersection(set(dt_columns))\n",
    "    assert len(set(text_columns).intersection(set(dt_columns)))==0, set(text_columns).intersection(set(dt_columns))\n",
    "    \n",
    "    for c in num_columns:\n",
    "        data[c].replace(\"A 'MySQL server has gone away' error was detected.  It is possible that there was an actual database issue, but it is more likely that REDCap detected this request as a duplicate and killed it.\", np.nan, inplace = True)\n",
    "        data[c] = data[c].astype(float)\n",
    "    data[text_columns] = data[text_columns].astype(str).replace('nan',np.nan)\n",
    "    \n",
    "    for c in dt_columns:\n",
    "        data[c] = pd.to_datetime(data[c])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff28ca04-5fb9-4074-8a5e-87c2dfd849b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "@get_efficiently\n",
    "def get_phone_data(self:DataProvider):\n",
    "    df = pd.read_csv(self.phonescreening_data_path,\n",
    "                     na_values = [\"A 'MySQL server has gone away' error was detected.  It is possible that there was an actual database issue, but it is more likely that REDCap detected this request as a duplicate and killed it.\"]\n",
    "                    )\n",
    "    remove = ['050571', '307493', '345678', '715736', 'Ihloff', 'test',\n",
    "       'test002', 'test003', 'test004', 'test005', 'test01', 'test02',\n",
    "       'test03', 'test0722', 'test1', 'test34', 'test999', 'test2020',\n",
    "       'test20201', 'test345345', 'testt', 'test_10', 'test_11_26',\n",
    "       'test_neu', 'xx956']\n",
    "    df = df[~df.participant_id.astype(str).isin(remove)]\n",
    "\n",
    "    bad_ids = df[~df.participant_id.apply(self.check_participant_id)].participant_id.unique()\n",
    "    assert len(bad_ids)==0, \"Bad participant IDs (should be added to remove): %s\"%', '.join([\"'%s'\"%b for b in bad_ids])\n",
    "    self.get_phone_codebook()\n",
    "    df = self.set_dtypes(df, self.get_phone_codebook())\n",
    "    df['participant_id'] = df.participant_id.astype(int)\n",
    "    df['center'] = df.screen_site.replace({1:'b',2:'d',3:'m'})\n",
    "    df['screen_date'] = pd.to_datetime(df['screen_date'], errors = 'coerce')\n",
    "    #display(df[df.screen_caller.isna()])\n",
    "    df = self.determine_phone_b07(df)    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafe0e84-520f-4cdb-bdc7-e7a6e7a9f4db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing phone_data\n"
     ]
    }
   ],
   "source": [
    "assert 'screen_caller' in dp.get_phone_data(update = True).columns, \"Failed to load phone data.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a2d1da-ddd7-49e4-a6fe-5d6c293a3ca0",
   "metadata": {},
   "source": [
    "### Getting baseline data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd2b434-1b5e-40f2-9b07-758d173bc083",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "@get_efficiently\n",
    "def get_ba_codebook(self:DataProvider):\n",
    "    tables = pd.read_html(open(self.ba_codebook_path,\"r\").read())\n",
    "    df = tables[1]\n",
    "    # Note that str.contains fills NaN values with nan, which can lead to strange results during filtering\n",
    "    df = df[df.LabelHinweistext.str.contains('Fragebogen:',na=False)==False]\n",
    "    df = df.set_index('#')\n",
    "    # Parsing variable name\n",
    "    df['variable'] = df[\"Variable / Feldname\"].apply(lambda x: x.split(' ')[0])\n",
    "    # Parsing condition under which variable is displayed\n",
    "    df['condition'] = df[\"Variable / Feldname\"].apply(lambda x: ' '.join(x.split(' ')[1:]).strip() if len(x.split(' '))>1 else '')\n",
    "    df['condition'] = df.condition.apply(lambda x: x.replace('Zeige das Feld nur wenn:  ',''))\n",
    "    # Parsing labels for numerical data\n",
    "    df['labels'] = np.nan\n",
    "    labels = tables[2:-1]\n",
    "    try:\n",
    "        labels = [dict(zip(l[0],l[1])) for l in labels]\n",
    "    except:\n",
    "        display(table)\n",
    "    searchfor = [\"radio\",\"dropdown\",\"yesno\",\"checkbox\"]\n",
    "    with_table = df['Feld Attribute (Feld-Typ, Prüfung, Auswahlen, Verzweigungslogik, Berechnungen, usw.)'].str.contains('|'.join(searchfor))\n",
    "    df.loc[with_table,'labels'] = labels\n",
    "    df = df.astype(str)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e15960a-506c-478f-96a1-59bef938cee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing ba_codebook\n"
     ]
    }
   ],
   "source": [
    "assert 'variable' in dp.get_ba_codebook(update = True), \"Codebook did not load correctly\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73fd17f4-30e4-4826-ad34-6aac61432a9c",
   "metadata": {},
   "source": [
    "> Warning: get_ba_data uses a different way to remove b07 participants.  This should be adjusted to use the same function as get_phone_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9074c02-9a2d-4e5f-b223-b2ab34dc62b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "@get_efficiently\n",
    "def get_ba_data(self:DataProvider):\n",
    "    '''This function reads in baseline data from redcap, filters out pilot data, and creates movisens IDs.'''\n",
    "    df = pd.read_csv(self.ba_data_path)\n",
    "    df['center'] = df.groupby('participant_id').bx_center.transform(lambda x: x.ffill().bfill())\n",
    "    df['center'] = df.center.replace({1:'b',2:'d',3:'m'})\n",
    "    # Creating new movisense IDs (adding center prefix to movisense IDs)\n",
    "    for old_id in ['bx_movisens','bx_movisens_old','bx_movisens_old_2']:\n",
    "        new_id = old_id.replace('bx_','').replace('movisens','mov_id')\n",
    "        df[new_id] = df.groupby('participant_id')[old_id].transform(lambda x: x.ffill().bfill())\n",
    "        df[new_id] = df.center + df[new_id].astype('str').str.strip('0').str.strip('.').apply(lambda x: x.zfill(3))\n",
    "        df[new_id].fillna('nan',inplace = True)\n",
    "        df.loc[df[new_id].str.contains('nan'),new_id] = np.nan\n",
    "    # Removing test participants \n",
    "    remove = ['050744', 'hdfghadgfh', 'LindaEngel', 'test', 'Test001', 'Test001a', 'test0011', 'test0012', 'test0013', 'test0014', 'test0015', 'test002', 'test00229', 'test007', 'test01', 'test012', 'test013', 'test1', 'test2', 'test4', 'test12', 'test999', 'test2021', 'test345345', 'testneu', 'testtest', 'test_0720', 'test_10', 'test_GA', 'Test_JH','test0016','891752080', 'pipingTest', 'test0001', 'test00012', 'test0012a', 'test0015a', 'test0017', 'test10', 'test20212', 'testJohn01', 'test_00213', 'test_00233', 'test_00271', 'test_003', 'test_004', 'test_11_26', 'Test_MS']\n",
    "    df = df[~df.participant_id.astype(str).isin(remove)]\n",
    "    # Checking participant ids (to find new test participants)\n",
    "    bad_ids = df[~df.participant_id.apply(self.check_participant_id)].participant_id.unique()\n",
    "    assert len(bad_ids)==0, \"Bad participant IDs (should be added to remove): %s\"%', '.join([\"'%s'\"%b for b in bad_ids])\n",
    "    # labeling B07 participant\n",
    "    b07_pps = pd.read_excel(self.b07_participants_path)['Participant ID'].astype(str)\n",
    "    df['is_b07'] = False\n",
    "    df.loc[df.participant_id.isin(b07_pps),'is_b07'] = True\n",
    "    # Setting dtypes based on codebook\n",
    "    df = self.set_dtypes(df, self.get_ba_codebook())\n",
    "    # Creating convenience variables\n",
    "    df['is_female'] = df.screen_gender.replace({1:True,2:False})\n",
    "    # Filling in missings from baseline\n",
    "    df['is_female'].fillna(df.bx_sozio_gender.replace({1:False,2:True}), inplace = True)\n",
    "    df['is_female'] = df.groupby('participant_id')['is_female'].transform(lambda x: x.ffill().bfill())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e09b8c7-dc87-47db-bb8f-7d66694f81eb",
   "metadata": {},
   "source": [
    "> ToDo: This should be defined as a \"slow test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179c1d1a-a695-4991-a220-14963b72dc63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing ba_data\n"
     ]
    }
   ],
   "source": [
    "check_ba = dp.get_ba_data(update = True)[['participant_id','redcap_event_name','redcap_repeat_instrument','redcap_repeat_instance']].value_counts().mean() == 1\n",
    "assert check_ba, \"Redcap BA data was not properly formatted\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91101dd2-403e-4bf9-9d1f-f3aa975ddfe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing ba_data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant_id</th>\n",
       "      <th>redcap_event_name</th>\n",
       "      <th>redcap_repeat_instrument</th>\n",
       "      <th>redcap_repeat_instance</th>\n",
       "      <th>redcap_survey_identifier</th>\n",
       "      <th>bx_pams</th>\n",
       "      <th>bx_exist120</th>\n",
       "      <th>study_id</th>\n",
       "      <th>bx_date</th>\n",
       "      <th>languages</th>\n",
       "      <th>...</th>\n",
       "      <th>bx_anruf_o2</th>\n",
       "      <th>bx_anruf_o2txt</th>\n",
       "      <th>bx_anruf_o3</th>\n",
       "      <th>anrufprotokoll_complete</th>\n",
       "      <th>center</th>\n",
       "      <th>mov_id</th>\n",
       "      <th>mov_id_old</th>\n",
       "      <th>mov_id_old_2</th>\n",
       "      <th>is_b07</th>\n",
       "      <th>is_female</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67</td>\n",
       "      <td>erhebungszeitpunkt_arm_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10101.0</td>\n",
       "      <td>2020-06-25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>d</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67</td>\n",
       "      <td>erhebungszeitpunkt_arm_1</td>\n",
       "      <td>at_home_qsu</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>d</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67</td>\n",
       "      <td>erhebungszeitpunkt_arm_1</td>\n",
       "      <td>at_home_bis15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>d</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>67</td>\n",
       "      <td>erhebungszeitpunkt_arm_1</td>\n",
       "      <td>at_home_cerq</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>d</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>67</td>\n",
       "      <td>erhebungszeitpunkt_arm_1</td>\n",
       "      <td>at_home_ad</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>d</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6748</th>\n",
       "      <td>11631</td>\n",
       "      <td>erhebungszeitpunkt_arm_1</td>\n",
       "      <td>at_home_oslo</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>m</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6749</th>\n",
       "      <td>11631</td>\n",
       "      <td>erhebungszeitpunkt_arm_1</td>\n",
       "      <td>at_home_pss10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>m</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6750</th>\n",
       "      <td>11631</td>\n",
       "      <td>erhebungszeitpunkt_arm_1</td>\n",
       "      <td>at_home_ucla</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>m</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6751</th>\n",
       "      <td>11631</td>\n",
       "      <td>erhebungszeitpunkt_arm_1</td>\n",
       "      <td>at_home_pain</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>m</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6752</th>\n",
       "      <td>11631</td>\n",
       "      <td>erhebungszeitpunkt_arm_1</td>\n",
       "      <td>at_home_sleep</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>m</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6753 rows × 3401 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     participant_id         redcap_event_name redcap_repeat_instrument  \\\n",
       "0                67  erhebungszeitpunkt_arm_1                      NaN   \n",
       "1                67  erhebungszeitpunkt_arm_1              at_home_qsu   \n",
       "2                67  erhebungszeitpunkt_arm_1            at_home_bis15   \n",
       "3                67  erhebungszeitpunkt_arm_1             at_home_cerq   \n",
       "4                67  erhebungszeitpunkt_arm_1               at_home_ad   \n",
       "...             ...                       ...                      ...   \n",
       "6748          11631  erhebungszeitpunkt_arm_1             at_home_oslo   \n",
       "6749          11631  erhebungszeitpunkt_arm_1            at_home_pss10   \n",
       "6750          11631  erhebungszeitpunkt_arm_1             at_home_ucla   \n",
       "6751          11631  erhebungszeitpunkt_arm_1             at_home_pain   \n",
       "6752          11631  erhebungszeitpunkt_arm_1            at_home_sleep   \n",
       "\n",
       "      redcap_repeat_instance  redcap_survey_identifier  bx_pams  bx_exist120  \\\n",
       "0                        NaN                       NaN      1.0          1.0   \n",
       "1                        1.0                       NaN      NaN          NaN   \n",
       "2                        1.0                       NaN      NaN          NaN   \n",
       "3                        1.0                       NaN      NaN          NaN   \n",
       "4                        1.0                       NaN      NaN          NaN   \n",
       "...                      ...                       ...      ...          ...   \n",
       "6748                     1.0                       NaN      NaN          NaN   \n",
       "6749                     1.0                       NaN      NaN          NaN   \n",
       "6750                     1.0                       NaN      NaN          NaN   \n",
       "6751                     1.0                       NaN      NaN          NaN   \n",
       "6752                     1.0                       NaN      NaN          NaN   \n",
       "\n",
       "     study_id    bx_date  languages  ...  bx_anruf_o2  bx_anruf_o2txt  \\\n",
       "0     10101.0 2020-06-25        NaN  ...          NaN             NaN   \n",
       "1         NaN        NaT        NaN  ...          NaN             NaN   \n",
       "2         NaN        NaT        NaN  ...          NaN             NaN   \n",
       "3         NaN        NaT        NaN  ...          NaN             NaN   \n",
       "4         NaN        NaT        NaN  ...          NaN             NaN   \n",
       "...       ...        ...        ...  ...          ...             ...   \n",
       "6748      NaN        NaT        NaN  ...          NaN             NaN   \n",
       "6749      NaN        NaT        NaN  ...          NaN             NaN   \n",
       "6750      NaN        NaT        NaN  ...          NaN             NaN   \n",
       "6751      NaN        NaT        NaN  ...          NaN             NaN   \n",
       "6752      NaN        NaT        NaN  ...          NaN             NaN   \n",
       "\n",
       "      bx_anruf_o3  anrufprotokoll_complete  center  mov_id  mov_id_old  \\\n",
       "0             NaN                      NaN       d     NaN         NaN   \n",
       "1             NaN                      NaN       d     NaN         NaN   \n",
       "2             NaN                      NaN       d     NaN         NaN   \n",
       "3             NaN                      NaN       d     NaN         NaN   \n",
       "4             NaN                      NaN       d     NaN         NaN   \n",
       "...           ...                      ...     ...     ...         ...   \n",
       "6748          NaN                      NaN       m     NaN         NaN   \n",
       "6749          NaN                      NaN       m     NaN         NaN   \n",
       "6750          NaN                      NaN       m     NaN         NaN   \n",
       "6751          NaN                      NaN       m     NaN         NaN   \n",
       "6752          NaN                      NaN       m     NaN         NaN   \n",
       "\n",
       "      mov_id_old_2  is_b07  is_female  \n",
       "0              NaN   False        1.0  \n",
       "1              NaN   False        1.0  \n",
       "2              NaN   False        1.0  \n",
       "3              NaN   False        1.0  \n",
       "4              NaN   False        1.0  \n",
       "...            ...     ...        ...  \n",
       "6748           NaN   False        0.0  \n",
       "6749           NaN   False        0.0  \n",
       "6750           NaN   False        0.0  \n",
       "6751           NaN   False        0.0  \n",
       "6752           NaN   False        0.0  \n",
       "\n",
       "[6753 rows x 3401 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp.get_ba_data(update = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4555c3-5739-48fb-a571-2f739d36e22c",
   "metadata": {},
   "source": [
    "### Getting Movisense data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc663495-183f-4847-8cef-8d775d11ecf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def get_duplicate_mov_ids(self:DataProvider):\n",
    "    '''This function creates a dictionary mapping old to new movisens IDs.'''\n",
    "    df = self.get_ba_data()\n",
    "    replace_dict_1 = dict(zip(df.mov_id_old, df.mov_id))\n",
    "    replace_dict_2 = dict(zip(df.mov_id_old_2, df.mov_id))\n",
    "    replace_dict = {**replace_dict_1, **replace_dict_2}\n",
    "    try:\n",
    "        del replace_dict[np.nan]\n",
    "    except:\n",
    "        pass\n",
    "    return replace_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23cd792-b3b8-45a6-8b7a-434df14bc357",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(dp.get_duplicate_mov_ids()), \"Could not load duplicate_mov_ids\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d73462-5c15-4b43-bbf7-d4d907186084",
   "metadata": {},
   "outputs": [],
   "source": [
    "@patch\n",
    "@get_efficiently\n",
    "def get_mov_data(self:DataProvider):\n",
    "    \"\"\"\n",
    "    This function gets Movisense data\n",
    "    1) We create unique participnat IDs (e.g. \"b001\"; this is necessary as sites use overapping IDs)\n",
    "    2) We merge double IDs, so participants with two IDs only have one (for this duplicate_ids.csv has to be updated)\n",
    "    3) We remove pilot participants\n",
    "    4) We get starting dates (from the participant overviews in movisense; downloaded as html)\n",
    "    5) We calculate sampling days and end dates based on the starting dates\n",
    "    \"\"\"\n",
    "    # Loading raw data\n",
    "    mov_berlin = pd.read_csv(os.path.join(get_raw(), \"mov_data_b.csv\"), sep = ';')\n",
    "    mov_dresden = pd.read_csv(os.path.join(get_raw(), \"mov_data_d.csv\"), sep = ';')\n",
    "    mov_mannheim = pd.read_csv(os.path.join(get_raw(), \"mov_data_m.csv\"), sep = ';')\n",
    "        \n",
    "    # Merging (participant numbers repeat so we add the first letter of location)\n",
    "    mov_berlin['location'] = 'berlin'\n",
    "    mov_dresden['location'] = 'dresden'\n",
    "    mov_mannheim['location'] = 'mannheim'\n",
    "    df = pd.concat([mov_berlin,mov_dresden,mov_mannheim])\n",
    "    df['participant'] =  df['location'].str[0] + df.Participant.apply(lambda x: '%03d'%int(x))\n",
    "    df['trigger_date'] = pd.to_datetime(df.Trigger_date + ' ' + df.Trigger_time)\n",
    "    \n",
    "    # Merging double IDs (for participants with several movisense IDs)\n",
    "    df['participant'] = df.participant.replace(get_duplicate_mov_ids())\n",
    "    \n",
    "    # Removing pilot participants\n",
    "    df = df[~df.Participant.astype(str).str.contains('test')]\n",
    "    df = df[~df.participant.isin(['m157'])]\n",
    "    \n",
    "    # Adding starting dates to get sampling days\n",
    "    def get_starting_dates(path, pp_prefix = ''):\n",
    "        soup = bs(open(path).read())\n",
    "        ids = [int(x.text) for x in soup.find_all(\"td\", class_ = 'simpleId')]\n",
    "        c_dates = [x.find_all(\"span\")[0]['title'] for x in soup.find_all(\"td\", class_ = 'coupleDate')]\n",
    "        s_dates = [x['value'] for x in soup.find_all(\"input\", class_ = 'dp startDate')]\n",
    "        df = pd.DataFrame({'participant':ids,'coupling_date':c_dates,'starting_date':s_dates})\n",
    "        df['coupling_date'] = pd.to_datetime(df.coupling_date)\n",
    "        df['starting_date'] = pd.to_datetime(df.starting_date)\n",
    "        df.starting_date.fillna(df.coupling_date,inplace = True)\n",
    "        df['participant'] = pp_prefix + df.participant.apply(lambda x: '%03d'%int(x))\n",
    "        return df\n",
    "    \n",
    "    starting_dates = pd.concat([\n",
    "    get_starting_dates(os.path.join(get_raw(), \"starting_dates_b.html\"), 'b'),\n",
    "    get_starting_dates(os.path.join(get_raw(), \"starting_dates_d.html\"), 'd'),\n",
    "    get_starting_dates(os.path.join(get_raw(), \"starting_dates_m.html\"), 'm')\n",
    "    ])\n",
    "    # For participants with several movisense IDs we use the first coupling date\n",
    "    starting_dates.participant.replace(get_duplicate_mov_ids(), inplace = True)\n",
    "    starting_dates = starting_dates.groupby('participant')[['starting_date','coupling_date']].min().reset_index()\n",
    "    df = df.merge(starting_dates, on=\"participant\", how = 'left', indicator = True)\n",
    "    # Checking if starting dates were downloaded\n",
    "    if \"left_only\" in df._merge.unique():\n",
    "        no_starting_dates = df.query('_merge == \"left_only\"').participant.unique()\n",
    "        print(\"Starting dates missing for participants below.  Did you download the participant overviews as html?\", no_starting_dates)\n",
    "    # Calculating movisense sampling day, adding date and end_date\n",
    "    df['sampling_day'] = (df['trigger_date'] - df['starting_date']).dt.days + 1\n",
    "    df['date'] = df.trigger_date.dt.date\n",
    "    df['end_date'] = df.date + pd.DateOffset(days = 365)\n",
    "    df.index.rename('mov_index',inplace = True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c101a8-7e02-41da-a6b3-56c9186dc7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 'starting_date' in get_mov_data().columns, \"Movisense data did not load correctly\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84042155-2a65-4c4a-8f03-89f0cb6f364c",
   "metadata": {},
   "source": [
    "#### Structure of movisense data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bead81b8-c61a-47d8-a9a3-1dcf9381696e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participant</th>\n",
       "      <th>participant</th>\n",
       "      <th>starting_date</th>\n",
       "      <th>Trigger</th>\n",
       "      <th>Trigger_date</th>\n",
       "      <th>Trigger_counter</th>\n",
       "      <th>Form</th>\n",
       "      <th>INT_Coverage_kleinesBier</th>\n",
       "      <th>INT_Coverage_kleinerWeisswein</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mov_index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>b001</td>\n",
       "      <td>2020-02-24</td>\n",
       "      <td>Button Pressed: Spiele starten und Initialfrag...</td>\n",
       "      <td>2020-02-24</td>\n",
       "      <td>9</td>\n",
       "      <td>Tag 1 Info</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>b001</td>\n",
       "      <td>2020-02-24</td>\n",
       "      <td>Fixed Time: 09:00</td>\n",
       "      <td>2020-02-24</td>\n",
       "      <td>11</td>\n",
       "      <td>Missing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>b001</td>\n",
       "      <td>2020-02-24</td>\n",
       "      <td>Fixed Time: 12:00</td>\n",
       "      <td>2020-02-24</td>\n",
       "      <td>17</td>\n",
       "      <td>Coverage</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>b001</td>\n",
       "      <td>2020-02-24</td>\n",
       "      <td>Fixed Time: 12:00</td>\n",
       "      <td>2020-02-24</td>\n",
       "      <td>17</td>\n",
       "      <td>Craving</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>b001</td>\n",
       "      <td>2020-02-24</td>\n",
       "      <td>Fixed Time: 12:00</td>\n",
       "      <td>2020-02-24</td>\n",
       "      <td>17</td>\n",
       "      <td>MDBF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200176</th>\n",
       "      <td>235</td>\n",
       "      <td>m235</td>\n",
       "      <td>2021-08-16</td>\n",
       "      <td>Button Pressed: Spiele starten und Initialfrag...</td>\n",
       "      <td>2021-08-16</td>\n",
       "      <td>16</td>\n",
       "      <td>Tag 1 Info</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200177</th>\n",
       "      <td>235</td>\n",
       "      <td>m235</td>\n",
       "      <td>2021-08-16</td>\n",
       "      <td>Button Pressed: Spiele starten und Initialfrag...</td>\n",
       "      <td>2021-08-16</td>\n",
       "      <td>16</td>\n",
       "      <td>Initial</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200178</th>\n",
       "      <td>235</td>\n",
       "      <td>m235</td>\n",
       "      <td>2021-08-16</td>\n",
       "      <td>Button Pressed: Spiele starten und Initialfrag...</td>\n",
       "      <td>2021-08-16</td>\n",
       "      <td>16</td>\n",
       "      <td>GBE_Tag1_Vorher</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200179</th>\n",
       "      <td>235</td>\n",
       "      <td>m235</td>\n",
       "      <td>2021-08-16</td>\n",
       "      <td>Button Pressed: Spiele starten und Initialfrag...</td>\n",
       "      <td>2021-08-16</td>\n",
       "      <td>16</td>\n",
       "      <td>GreatBrainExperiment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200180</th>\n",
       "      <td>235</td>\n",
       "      <td>m235</td>\n",
       "      <td>2021-08-16</td>\n",
       "      <td>Button Pressed: Spiele starten und Initialfrag...</td>\n",
       "      <td>2021-08-16</td>\n",
       "      <td>16</td>\n",
       "      <td>GreatBrainExperiment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200181 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Participant participant starting_date  \\\n",
       "mov_index                                          \n",
       "0                    1        b001    2020-02-24   \n",
       "1                    1        b001    2020-02-24   \n",
       "2                    1        b001    2020-02-24   \n",
       "3                    1        b001    2020-02-24   \n",
       "4                    1        b001    2020-02-24   \n",
       "...                ...         ...           ...   \n",
       "200176             235        m235    2021-08-16   \n",
       "200177             235        m235    2021-08-16   \n",
       "200178             235        m235    2021-08-16   \n",
       "200179             235        m235    2021-08-16   \n",
       "200180             235        m235    2021-08-16   \n",
       "\n",
       "                                                     Trigger Trigger_date  \\\n",
       "mov_index                                                                   \n",
       "0          Button Pressed: Spiele starten und Initialfrag...   2020-02-24   \n",
       "1                                          Fixed Time: 09:00   2020-02-24   \n",
       "2                                          Fixed Time: 12:00   2020-02-24   \n",
       "3                                          Fixed Time: 12:00   2020-02-24   \n",
       "4                                          Fixed Time: 12:00   2020-02-24   \n",
       "...                                                      ...          ...   \n",
       "200176     Button Pressed: Spiele starten und Initialfrag...   2021-08-16   \n",
       "200177     Button Pressed: Spiele starten und Initialfrag...   2021-08-16   \n",
       "200178     Button Pressed: Spiele starten und Initialfrag...   2021-08-16   \n",
       "200179     Button Pressed: Spiele starten und Initialfrag...   2021-08-16   \n",
       "200180     Button Pressed: Spiele starten und Initialfrag...   2021-08-16   \n",
       "\n",
       "           Trigger_counter                  Form  INT_Coverage_kleinesBier  \\\n",
       "mov_index                                                                    \n",
       "0                        9            Tag 1 Info                       NaN   \n",
       "1                       11               Missing                       NaN   \n",
       "2                       17              Coverage                       NaN   \n",
       "3                       17               Craving                       NaN   \n",
       "4                       17                  MDBF                       NaN   \n",
       "...                    ...                   ...                       ...   \n",
       "200176                  16            Tag 1 Info                       NaN   \n",
       "200177                  16               Initial                       NaN   \n",
       "200178                  16       GBE_Tag1_Vorher                       NaN   \n",
       "200179                  16  GreatBrainExperiment                       NaN   \n",
       "200180                  16  GreatBrainExperiment                       NaN   \n",
       "\n",
       "           INT_Coverage_kleinerWeisswein  \n",
       "mov_index                                 \n",
       "0                                    NaN  \n",
       "1                                    NaN  \n",
       "2                                    NaN  \n",
       "3                                    NaN  \n",
       "4                                    NaN  \n",
       "...                                  ...  \n",
       "200176                               NaN  \n",
       "200177                               NaN  \n",
       "200178                               NaN  \n",
       "200179                               NaN  \n",
       "200180                               NaN  \n",
       "\n",
       "[200181 rows x 9 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_mov_data()[['Participant','participant','starting_date','Trigger','Trigger_date','Trigger_counter','Form','INT_Coverage_kleinesBier','INT_Coverage_kleinerWeisswein']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e879a497-d136-47b9-9e9e-f0e6cdc32784",
   "metadata": {},
   "source": [
    "### Getting two-day data\n",
    "This is a subset of the movisense data (only the two-daily questions), which we reformat so that each day is one one line.  We also add nan data for dates after the last data was received until 365 days until the starting date.  We rearrange answers to retrospective questions, so they are associated with the date in question rather than the date on which the question was answered.  For example, the answer to the question \"How many beers did you drink two days ago\" gets shifted two days back from the date of the question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29cf8fc8-19ef-4a19-8995-da79547a61ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "@patch\n",
    "def get_alcohol_per_drink(self:DataProvider):\n",
    "    path = os.path.join(get_external(),'alcohol_per_drink.csv')\n",
    "    if not os.path.isfile(path):\n",
    "        return None\n",
    "    else:\n",
    "        return pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9773301-5f61-4758-a783-0e09e5539e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert type(get_alcohol_per_drink()) == type(pd.DataFrame()), \"Could not load 'alcohol_per_drink.csv' from external data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2824683-9fa8-4ce7-803b-e82907a4493d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@patch\n",
    "@get_efficiently\n",
    "def get_two_day_data(self:DataProvider):\n",
    "    \"\"\"Gets two-day which are a subset of mov_data\n",
    "    1) We select two-day forms and turn the dataframe into one row per participant-date (Form repetitions on the same day are removed)\n",
    "    2) We reduce all drinking questions to an easily readable dictionary of drink amounts.\n",
    "    3) We add missing data for dates on which we did not receive answers (starting 2 days before starting date up to 365 days after)\n",
    "    4) We shift answers from retrospective drinking questions backwards to the adequate date (e.g. one day back for yesterday questions) \n",
    "    \"\"\"\n",
    "    mov_data = get_mov_data().reset_index()\n",
    "    drinking_columns = [c for c in mov_data.columns if c.startswith(\"Anzahl\") and \"10day\" not in c]\n",
    "    mdbf_columns = [c for c in mov_data.columns if \"MDBF\" in c and \"INT\" not in c]\n",
    "    two_day_columns = ['mov_index','starting_date','end_date','sampling_day'] + drinking_columns + mdbf_columns + ['soziale_isolation','alternative_rewards','craving','Limit','Kontrolle']\n",
    "    # 1) Turning df into one line per date\n",
    "    two_day_forms = [\"Coverage\",\"Soziale Isolation\",\"Craving\",\"MDBF\",\"Alternative Rewards\",\"Limits & Control\"]\n",
    "    df = mov_data.sort_values(by=['participant','trigger_date','Form','Trigger_counter'])\n",
    "    df = df[df.Form.isin(two_day_forms)].groupby([\"participant\",\"date\"])[two_day_columns].first().dropna(how='all').reset_index()\n",
    "    # 2) Turning drinking answers into dictionaries\n",
    "    df[drinking_columns].fillna(0,inplace = True)\n",
    "    df['drinks_gestern'] = df[[c for c in drinking_columns if \"vorgestern\" not in c]].fillna(0).agg(lambda x: x.to_dict(), axis=1)\n",
    "    df['drinks_vorgestern'] = df[[c for c in drinking_columns if \"vorgestern\" in c]].fillna(0).agg(lambda x: x.to_dict(), axis=1)\n",
    "    # Adding missing values\n",
    "    def add_missing_data(df):\n",
    "        dates = pd.date_range(df.starting_date.iloc[0]-pd.DateOffset(days = 2), df.end_date.iloc[0])\n",
    "        df = df.reindex(dates)\n",
    "        df.index.names = ['date']\n",
    "        df[['starting_date','sampling_day']] = df[['starting_date','sampling_day']].bfill().ffill()\n",
    "        return df\n",
    "    df = df.set_index('date').groupby('participant').apply(add_missing_data).drop(columns='participant').reset_index()\n",
    "    \n",
    "    # 3) Shifting back retrospective answers\n",
    "    df['drinks'] = df['drinks_gestern'].shift(-1) # Drinks yesterday get shifted back one day\n",
    "    df['drinks'].fillna(df['drinks_vorgestern'].shift(-2), inplace = True) # Drinks before yesterday shift back two days\n",
    "    df['limit'] = df.Limit.ffill(limit=8) # Limit gets repeated forward for eight days\n",
    "    df['control'] = df.Kontrolle.bfill(limit=8) # Control is repeated backward for eight days\n",
    "    # 4) Calculating daily alcohol consumption in grams\n",
    "    alc_dict = {\"Anzahl\"+k:v for k,v in get_alcohol_per_drink().set_index('drink')['ml_alc_per_drink'].to_dict().items()}\n",
    "    def calculate_g_alc(x):\n",
    "        if x != x:\n",
    "            ml_alc = np.nan\n",
    "        else:\n",
    "            ml_alc = 0\n",
    "            for k,v in x.items():\n",
    "                if v > 0:\n",
    "                    ml_alc += alc_dict[k.split('_')[0]] * v\n",
    "        return ml_alc * .8\n",
    "    df['g_alc']  = df.drinks.apply(calculate_g_alc)\n",
    "    # Returning relevant columns only\n",
    "    df = df.reset_index()\n",
    "    df['sampling_day'] = df.groupby('participant').starting_date.cumcount() + 1\n",
    "    df.index.rename('two_day_index',inplace = True)\n",
    "    return df[['mov_index','participant','starting_date','date','sampling_day'] + mdbf_columns + ['soziale_isolation','alternative_rewards','craving','limit','control','drinks','g_alc']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89993eaf-aa86-4b25-9d87-b1a63d5cacca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_one_line_per_participant_day():\n",
    "    return get_two_day_data().groupby(['participant','date']).date.count().value_counts().index[0] == 1\n",
    "\n",
    "assert test_one_line_per_participant_day(), \"Two day data does not have one line per participant day.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c63c32-af1a-48f1-b0be-a94f62793e2c",
   "metadata": {},
   "source": [
    "#### Structure of two-day data\n",
    "> Warning: Note that sampling days run further than 365.  This should not be the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1782c327-cd94-4f14-a760-aab316661347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing two_day_data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mov_index</th>\n",
       "      <th>participant</th>\n",
       "      <th>date</th>\n",
       "      <th>starting_date</th>\n",
       "      <th>sampling_day</th>\n",
       "      <th>soziale_isolation</th>\n",
       "      <th>drinks</th>\n",
       "      <th>g_alc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>two_day_index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>b001</td>\n",
       "      <td>2020-02-22</td>\n",
       "      <td>2020-02-24</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'AnzahlKleinesBier_vorgestern': 0.0, 'AnzahlM...</td>\n",
       "      <td>6.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>b001</td>\n",
       "      <td>2020-02-23</td>\n",
       "      <td>2020-02-24</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'AnzahlKleinesBier': 0.0, 'AnzahlMittlereBier...</td>\n",
       "      <td>35.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.0</td>\n",
       "      <td>b001</td>\n",
       "      <td>2020-02-24</td>\n",
       "      <td>2020-02-24</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>b001</td>\n",
       "      <td>2020-02-25</td>\n",
       "      <td>2020-02-24</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>b001</td>\n",
       "      <td>2020-02-26</td>\n",
       "      <td>2020-02-24</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139779</th>\n",
       "      <td>NaN</td>\n",
       "      <td>m234</td>\n",
       "      <td>2022-08-12</td>\n",
       "      <td>2021-08-16</td>\n",
       "      <td>364</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139780</th>\n",
       "      <td>NaN</td>\n",
       "      <td>m234</td>\n",
       "      <td>2022-08-13</td>\n",
       "      <td>2021-08-16</td>\n",
       "      <td>365</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139781</th>\n",
       "      <td>NaN</td>\n",
       "      <td>m234</td>\n",
       "      <td>2022-08-14</td>\n",
       "      <td>2021-08-16</td>\n",
       "      <td>366</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139782</th>\n",
       "      <td>NaN</td>\n",
       "      <td>m234</td>\n",
       "      <td>2022-08-15</td>\n",
       "      <td>2021-08-16</td>\n",
       "      <td>367</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139783</th>\n",
       "      <td>NaN</td>\n",
       "      <td>m234</td>\n",
       "      <td>2022-08-16</td>\n",
       "      <td>2021-08-16</td>\n",
       "      <td>368</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>139784 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               mov_index participant       date starting_date  sampling_day  \\\n",
       "two_day_index                                                                 \n",
       "0                    NaN        b001 2020-02-22    2020-02-24             1   \n",
       "1                    NaN        b001 2020-02-23    2020-02-24             2   \n",
       "2                    6.0        b001 2020-02-24    2020-02-24             3   \n",
       "3                    NaN        b001 2020-02-25    2020-02-24             4   \n",
       "4                    NaN        b001 2020-02-26    2020-02-24             5   \n",
       "...                  ...         ...        ...           ...           ...   \n",
       "139779               NaN        m234 2022-08-12    2021-08-16           364   \n",
       "139780               NaN        m234 2022-08-13    2021-08-16           365   \n",
       "139781               NaN        m234 2022-08-14    2021-08-16           366   \n",
       "139782               NaN        m234 2022-08-15    2021-08-16           367   \n",
       "139783               NaN        m234 2022-08-16    2021-08-16           368   \n",
       "\n",
       "               soziale_isolation  \\\n",
       "two_day_index                      \n",
       "0                            NaN   \n",
       "1                            NaN   \n",
       "2                            1.0   \n",
       "3                            NaN   \n",
       "4                            NaN   \n",
       "...                          ...   \n",
       "139779                       NaN   \n",
       "139780                       NaN   \n",
       "139781                       NaN   \n",
       "139782                       NaN   \n",
       "139783                       NaN   \n",
       "\n",
       "                                                          drinks  g_alc  \n",
       "two_day_index                                                            \n",
       "0              {'AnzahlKleinesBier_vorgestern': 0.0, 'AnzahlM...    6.4  \n",
       "1              {'AnzahlKleinesBier': 0.0, 'AnzahlMittlereBier...   35.2  \n",
       "2                                                            NaN    NaN  \n",
       "3                                                            NaN    NaN  \n",
       "4                                                            NaN    NaN  \n",
       "...                                                          ...    ...  \n",
       "139779                                                       NaN    NaN  \n",
       "139780                                                       NaN    NaN  \n",
       "139781                                                       NaN    NaN  \n",
       "139782                                                       NaN    NaN  \n",
       "139783                                                       NaN    NaN  \n",
       "\n",
       "[139784 rows x 8 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_two_day_data(update = True)[['mov_index','participant','date','starting_date','sampling_day','soziale_isolation','drinks','g_alc']]#.iloc[:20]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
