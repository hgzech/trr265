{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c29c9ff-5273-4bd1-9952-b1ef8a7c8d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp data_provider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82658e0-1f45-4e64-9b6e-9090f8508fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from fastcore.foundation import patch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8955535-3f82-4a44-bd5e-1588c7338cfd",
   "metadata": {},
   "source": [
    "# Data Provider\n",
    "\n",
    "> This module is responsible for processing raw TRR data for further analysis. ToDo: This code should be formatted as a class that gets the data folder path on init."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ae00df-b3fa-42f0-b47c-8f952c9dd5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class DataProvider():\n",
    "    def __init__(self, data_folder_path):\n",
    "        self.data_folder_path = data_folder_path\n",
    "        self.raw = os.path.join(data_folder_path, 'raw')\n",
    "        self.external = os.path.join(data_folder_path, 'external')\n",
    "        self.interim = os.path.join(data_folder_path, 'interim')\n",
    "        self.processed = os.path.join(data_folder_path, 'processed')\n",
    "        # Checking if folder paths exist\n",
    "        assert os.path.isdir(self.external), \"External data folder not found.\"\n",
    "        assert os.path.isdir(self.raw), \"Raw data folder not found.\"\n",
    "        assert os.path.isdir(self.interim), \"Interim data folder not found.\"\n",
    "        assert os.path.isdir(self.processed), \"Processed data folder not found.\"\n",
    "        # Phone screening files\n",
    "        self.phonescreening_data_path = os.path.join(self.raw, \"phonescreening.csv\")\n",
    "        self.phone_codebook_path = os.path.join(self.external, \"phone_codebook.html\")\n",
    "        # Basic assessment files\n",
    "        self.ba_codebook_path = os.path.join(self.external, \"ba_codebook.html\")\n",
    "        self.ba_data_path = os.path.join(self.raw, \"ba.csv\")\n",
    "        self.b07_participants_path = os.path.join(self.external, \"b7_participants.xlsx\")\n",
    "        # Movisense data\n",
    "        self.mov_berlin_path = os.path.join(self.raw, \"mov_data_b.csv\")\n",
    "        self.mov_dresden_path = os.path.join(self.raw, \"mov_data_d.csv\")\n",
    "        self.mov_mannheim_path = os.path.join(self.raw, \"mov_data_m.csv\")\n",
    "        self.mov_berlin_starting_dates_path = os.path.join(self.raw, \"starting_dates_b.html\")\n",
    "        self.mov_dresden_starting_dates_path = os.path.join(self.raw, \"starting_dates_d.html\")\n",
    "        self.mov_mannheim_starting_dates_path = os.path.join(self.raw, \"starting_dates_m.html\")\n",
    "        self.alcohol_per_drink_path = os.path.join(self.external,'alcohol_per_drink.csv')\n",
    "\n",
    "        \n",
    "#export\n",
    "def get_efficiently(func):\n",
    "    \"\"\"\n",
    "    This decorator wraps around functions that get data and handles data storage.\n",
    "    If the output from the function hasn't been stored yet, it stores it in \"[path_to_interim]/[function_name_without_get].parquet\"\n",
    "    If the output from the function has been stored already, it loads the stored file instead of running the function (unless update is specified as True)\n",
    "    \"\"\"\n",
    "    def w(*args, update = False, columns = None, path = None, **kw):\n",
    "        _self = args[0] # Getting self to grab interim path from DataProvider\n",
    "        var_name = func.__name__.replace('__get_','').replace('get_','')\n",
    "        file_path = os.path.join(_self.interim, \"%s.parquet\"%var_name)\n",
    "        if os.path.exists(file_path) and (update == False):\n",
    "            result =  pd.read_parquet(file_path, columns = columns)\n",
    "        else:\n",
    "            print(\"Preparing %s\"%var_name)\n",
    "            result = func(_self)\n",
    "            result.to_parquet(file_path)\n",
    "        return result\n",
    "    w.__wrapped__ = func # Specifying the wrapped function for inspection\n",
    "    w.__doc__ = func.__doc__\n",
    "    w.__name__ = func.__name__\n",
    "    w.__annotations__ = {'cls':DataProvider, 'as_prop':False} # Adding parameters to make this work with @patch\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ebd203-05ed-4da7-9a78-20f0bc31f21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dp = DataProvider('/Users/hilmarzech/Projects/trr265/trr265/data/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada8fe42-eee8-4938-b729-897c1d50412e",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bbd6bf-0a55-4111-b8d4-d352acbb9c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def store_interim(self:DataProvider, df, filename):\n",
    "    path = os.path.join(self.interim,\"%s.parquet\"%filename)\n",
    "    df.to_parquet(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5865e3c8-7327-4474-8ed7-e3588c748e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def load_interim(self:DataProvider, filename):\n",
    "    return pd.read_parquet(os.path.join(self.interim,\"%s.parquet\"%filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e27e5e-a062-4a4b-a328-9e28cbcf4b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def storing_test(dp):\n",
    "    df = pd.DataFrame({\"test\":[4]})\n",
    "    # Storing the dataframe\n",
    "    dp.store_interim(df, 'storing_test')\n",
    "    # Reloading it and comparing to original\n",
    "    return df.equals(dp.load_interim('storing_test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afba6ab-375c-4c7c-ba6a-daeb4d82085c",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert storing_test(dp), \"Data storage is failing.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba56b438-5e7e-48e8-9b5b-1f034d5f094b",
   "metadata": {},
   "source": [
    "### Getting phone screening data\n",
    "> This functions get the phone screening data from redcap.  To run them, first go to redcap and download the phonescreening data to 'raw/phonescreening.csv' and the phonescreening codebook to 'external/phone_codebook.html'.  You also need the external/b7_participants.xlsx (if it's not in the cloned package, ask Hilmar for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e006e1c2-3323-493a-824f-8f0c41933ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "@get_efficiently\n",
    "def get_phone_codebook(self:DataProvider):\n",
    "    tables = pd.read_html(open(self.phone_codebook_path,'r').read())\n",
    "    df = tables[1]\n",
    "    # Note that str.contains fills NaN values with nan, which can lead to strange results during filtering\n",
    "    df = df[df.LabelHinweistext.str.contains('Fragebogen:',na=False)==False]\n",
    "    df = df.set_index('#')\n",
    "    # Parsing variable name\n",
    "    df['variable'] = df[\"Variable / Feldname\"].apply(lambda x: x.split(' ')[0])\n",
    "    # Parsing condition under which variable is displayed\n",
    "    df['condition'] = df[\"Variable / Feldname\"].apply(lambda x: ' '.join(x.split(' ')[1:]).strip() if len(x.split(' '))>1 else '')\n",
    "    df['condition'] = df.condition.apply(lambda x: x.replace('Zeige das Feld nur wenn:  ',''))\n",
    "    # Parsing labels for numerical data\n",
    "    df['labels'] = np.nan\n",
    "    labels = tables[2:-1]\n",
    "    try:\n",
    "        labels = [dict(zip(l[0],l[1])) for l in labels]\n",
    "    except:\n",
    "        display(table)\n",
    "    searchfor = [\"radio\",\"dropdown\",\"yesno\",\"checkbox\"]\n",
    "    with_table = df['Feld Attribute (Feld-Typ, Prüfung, Auswahlen, Verzweigungslogik, Berechnungen, usw.)'].str.contains('|'.join(searchfor))\n",
    "    df.loc[with_table,'labels'] = labels\n",
    "    df = df.astype(str)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66da2adf-b8cb-4406-8432-c014118de059",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 'participant_id' in dp.get_phone_codebook().variable.values, \"Failed to load phone_codebook.html\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560ed51b-7c8d-4cc3-9244-6288ebe436c1",
   "metadata": {},
   "source": [
    "> Initially, participants from b07 were stored in the same RedCap project as S01 participants.  This function attempts to disentangle the two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e61704b-bde0-4082-8ca7-5d1025a43180",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "@patch\n",
    "def determine_phone_b07(self:DataProvider, df):\n",
    "    # Some initial fixes\n",
    "    df.loc[df.center=='d','screen_caller'] = df.loc[df.center=='d','screen_caller'].str.lower().str.strip().replace('leo','leonard visser').replace('sebastian mörcke','sebastian möricke').replace('jessica zimmerman','jessica zimmermann').replace('miriam-sophie petasch','miriam petasch').replace('dorothee','dorothee scheuermann')\n",
    "    # Cleaning screener list\n",
    "    dd_screeners = df[(df.center=='d')&(df.screen_caller.isna()==False)].screen_caller.unique()\n",
    "    def clean_screeners(dd_screeners):\n",
    "        dd_screeners = [y  for x in dd_screeners for y in x.split('+')]\n",
    "        dd_screeners = [y  for x in dd_screeners for y in x.split(',')]\n",
    "        dd_screeners = [y  for x in dd_screeners for y in x.split('und')]\n",
    "        dd_screeners = [y.replace('(15.02.21)','')  for x in dd_screeners for y in x.split('/')]\n",
    "        dd_screeners = [y.replace(')','').strip().lower()  for x in dd_screeners for y in x.split('(')]\n",
    "        dd_screeners = sorted(list(set(dd_screeners)))\n",
    "        return dd_screeners\n",
    "    dd_screeners = clean_screeners(dd_screeners)\n",
    "    \n",
    "    b07_screeners = ['ann-kathrin stock','charlotte blum','josephine kirschgens','klara macht','borchardt','marta ledro','miriam petasch','mona hofmann','theo tester']\n",
    "    s01_screeners = ['esther preuschhof', 'miriam schmitz', 'sebastian möricke', 'jessica zimmermann', 'leonard visser', 'anna-lena lünert', 'anne dörfler', 'dominic reichert', 'maike borchardt', 'dorothee scheuermann', 'paula böhlmann', 'alice','josephine kirschgens maxi stiller', 'maria schießl', '22.10.2021', 'sascha', '03.08.2021', 'mariana plumbohm', 'caroline neumer', '04.08.2021', 'maxi stiller', 'sacsha', '09.08.2021', 'ml', 'charlotte', 'charlotte heinze', 'shereen', 'test', \"charlotte heinze\", 'benedikt']\n",
    "    known_dd_screeners = list(b07_screeners+s01_screeners)\n",
    "    dd_screeners = df[(df.center=='d')&(df.screen_caller.isna()==False)].screen_caller.unique()\n",
    "    # Checking if all Dresden phone screeners are accounted for\n",
    "    assert df[(df.center=='d')&(df.screen_caller)].screen_caller.str.contains('|'.join(known_dd_screeners)).mean()==1, \"Unknown Dresden phone screener: %s\"%', '.join(set(clean_screeners(dd_screeners))-set(known_dd_screeners))\n",
    "    # In general, if a screener from a project was involved, it was screened for that project\n",
    "    df['screened_for_b07'] = (df.center=='d') & (df.screen_caller.str.contains('|'.join(b07_screeners)))\n",
    "    df['screened_for_s01'] = (df.center!='d') | (df.screen_caller.str.contains('|'.join(s01_screeners)))\n",
    "    \n",
    "    # We also exclude participants screened for C02 in Berlin\n",
    "    df.loc[(df.screen_purpose == 4) & (df.center=='b'), 'screened_for_s01'] = False\n",
    "    \n",
    "    # Additionally, we also set it to true if it was specifically set\n",
    "    df.loc[df.screen_site_dd == 1, 'screened_for_s01'] = True\n",
    "    df.loc[df.screen_site_dd == 3, 'screened_for_s01'] = True\n",
    "    df.loc[df.screen_site_dd == 2, 'screened_for_b07'] = True\n",
    "    df.loc[df.screen_site_dd == 3, 'screened_for_b07'] = True\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f792bc63-1988-43ea-9e6d-36297a98679d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def check_participant_id(self:DataProvider,x):\n",
    "    '''This function checks whether a participant ID is numerical and lower than 20000.'''\n",
    "    if str(x) == x:\n",
    "        if x.isnumeric():\n",
    "            x = float(x)\n",
    "        else:\n",
    "            return False\n",
    "    if x > 20000:\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e10dd6b-d759-4a74-8f35-a214614917cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def test_check_participant_id(self:DataProvider):\n",
    "    failed = dp.check_participant_id('test10') == False # Example of a bad participant ID\n",
    "    passed = dp.check_participant_id('100') == True # Example of a good participant ID\n",
    "    return failed and passed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f904a93-8d56-4f33-9214-5468b64a0fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert dp.test_check_participant_id(), \"Participant ID check is not working\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9fd271-7607-46d6-aa38-6947203fe60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def set_dtypes(self:DataProvider, data, codebook):\n",
    "    def number_or_nan(x):\n",
    "        try:\n",
    "            float(x)\n",
    "            return x\n",
    "        except:\n",
    "            return np.nan\n",
    "    '''This function automatically adjust data types of redcap data based on the redcap codebooks'''\n",
    "    # Parsing type\n",
    "    codebook['type'] = codebook[\"Feld Attribute (Feld-Typ, Prüfung, Auswahlen, Verzweigungslogik, Berechnungen, usw.)\"].apply(lambda x: x.split(',')[0]) \n",
    "    # Descriptives (not in data)\n",
    "    desc_columns = list(codebook[codebook.type.str.contains('descriptive')].variable)\n",
    "    # Datetime\n",
    "    dt_columns = codebook[(codebook.type.isin(['text (datetime_dmy)','text (date_dmy)']))].variable\n",
    "    dt_columns = list(set(data.columns).intersection(dt_columns))\n",
    "    # Numerical\n",
    "    num_columns = []\n",
    "    num_columns += list(codebook[codebook.type.str.contains('calc')].variable)\n",
    "    num_columns += list(codebook[codebook.type.str.contains('checkbox')].variable)\n",
    "    num_columns += list(codebook[codebook.type.str.contains('radio')].variable)\n",
    "    num_columns += list(codebook[codebook.type.str.contains('text \\(number')].variable)\n",
    "    num_columns += list(codebook[codebook.type.str.contains('yesno')].variable)\n",
    "    num_columns += list(codebook[codebook.type.str.contains('dropdown')].variable)\n",
    "    num_columns += list(codebook[codebook.type.str.contains('slider')].variable)\n",
    "    num_columns = list(set(data.columns).intersection(num_columns))\n",
    "    # Text\n",
    "    text_columns = []\n",
    "    text_columns += list(codebook[(codebook.type.str.contains('text')) & (~codebook.type.str.contains('date_dmy|datetime_dmy'))].variable)\n",
    "    text_columns += list(codebook[(codebook.type.str.contains('notes'))].variable)\n",
    "    text_columns += list(codebook[(codebook.type.str.contains('file'))].variable)\n",
    "    text_columns = list(set(data.columns).intersection(text_columns))\n",
    "    assert len(set(num_columns).intersection(set(dt_columns)))==0, set(num_columns).intersection(set(dt_columns))\n",
    "    assert len(set(text_columns).intersection(set(dt_columns)))==0, set(text_columns).intersection(set(dt_columns))\n",
    "\n",
    "\n",
    "\n",
    "    for c in num_columns:\n",
    "        data[c].replace(\"A 'MySQL server has gone away' error was detected.  It is possible that there was an actual database issue, but it is more likely that REDCap detected this request as a duplicate and killed it.\", np.nan, inplace = True)\n",
    "        try:\n",
    "            data[c] = data[c].astype(float)\n",
    "        except:\n",
    "            data[c] = data[c].apply(number_or_nan).astype(float)\n",
    "            print(\"Values with wrong dtype in %s\"%c)\n",
    "    data[text_columns] = data[text_columns].astype(str).replace('nan',np.nan)\n",
    "    \n",
    "    for c in dt_columns:\n",
    "        data[c] = pd.to_datetime(data[c])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff28ca04-5fb9-4074-8a5e-87c2dfd849b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "@get_efficiently\n",
    "def get_phone_data(self:DataProvider):\n",
    "    df = pd.read_csv(self.phonescreening_data_path,\n",
    "                     na_values = [\"A 'MySQL server has gone away' error was detected.  It is possible that there was an actual database issue, but it is more likely that REDCap detected this request as a duplicate and killed it.\"]\n",
    "                    )\n",
    "    remove = ['050571', '307493', '345678', '715736', 'Ihloff', 'test',\n",
    "       'test002', 'test003', 'test004', 'test005', 'test01', 'test02',\n",
    "       'test03', 'test0722', 'test1', 'test34', 'test999', 'test2020',\n",
    "       'test20201', 'test345345', 'testt', 'test_10', 'test_11_26',\n",
    "       'test_neu', 'xx956','050262', '050335', '050402', '050416', '051005', '294932', '891752080', '898922719', '898922899', '917702419', '01627712983', 'meow', 'test0022', 'test246', 'test5647', 'test22222', 'test41514', 'testtt', 'test_057', 'tets','898923271', 'test001', 'test006', 'test007', 'test008', 'test11', 'test_23_12', 'test_n']\n",
    "    df = df[~df.participant_id.astype(str).isin(remove)]\n",
    "\n",
    "    bad_ids = df[~df.participant_id.apply(self.check_participant_id)].participant_id.unique()\n",
    "    assert len(bad_ids)==0, \"Bad participant IDs (should be added to remove): %s\"%', '.join([\"'%s'\"%b for b in bad_ids])\n",
    "    self.get_phone_codebook()\n",
    "    df = self.set_dtypes(df, self.get_phone_codebook())\n",
    "    df['participant_id'] = df.participant_id.astype(int)\n",
    "    df['center'] = df.screen_site.replace({1:'b',2:'d',3:'m'})\n",
    "    df['screen_date'] = pd.to_datetime(df['screen_date'], errors = 'coerce')\n",
    "    #display(df[df.screen_caller.isna()])\n",
    "    df = self.determine_phone_b07(df)    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafe0e84-520f-4cdb-bdc7-e7a6e7a9f4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 'screen_caller' in dp.get_phone_data().columns, \"Failed to load phone data.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a2d1da-ddd7-49e4-a6fe-5d6c293a3ca0",
   "metadata": {},
   "source": [
    "### Getting baseline data\n",
    "> Warning: This function does not work if the computers default encoding is not UTF-8 -> This should be adjusted in pd.readhtml..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd2b434-1b5e-40f2-9b07-758d173bc083",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "@get_efficiently\n",
    "def get_ba_codebook(self:DataProvider):\n",
    "    tables = pd.read_html(open(self.ba_codebook_path,\"r\").read())\n",
    "    df = tables[1]\n",
    "    # Note that str.contains fills NaN values with nan, which can lead to strange results during filtering\n",
    "    df = df[df.LabelHinweistext.str.contains('Fragebogen:',na=False)==False]\n",
    "    df = df.set_index('#')\n",
    "    # Parsing variable name\n",
    "    df['variable'] = df[\"Variable / Feldname\"].apply(lambda x: x.split(' ')[0])\n",
    "    # Parsing condition under which variable is displayed\n",
    "    df['condition'] = df[\"Variable / Feldname\"].apply(lambda x: ' '.join(x.split(' ')[1:]).strip() if len(x.split(' '))>1 else '')\n",
    "    df['condition'] = df.condition.apply(lambda x: x.replace('Zeige das Feld nur wenn:  ',''))\n",
    "    # Parsing labels for numerical data\n",
    "    df['labels'] = np.nan\n",
    "    labels = tables[2:-1]\n",
    "    try:\n",
    "        labels = [dict(zip(l[0],l[1])) for l in labels]\n",
    "    except:\n",
    "        display(table)\n",
    "    searchfor = [\"radio\",\"dropdown\",\"yesno\",\"checkbox\"]\n",
    "    with_table = df['Feld Attribute (Feld-Typ, Prüfung, Auswahlen, Verzweigungslogik, Berechnungen, usw.)'].str.contains('|'.join(searchfor))\n",
    "    df.loc[with_table,'labels'] = labels\n",
    "    df = df.astype(str)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e15960a-506c-478f-96a1-59bef938cee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 'variable' in dp.get_ba_codebook(), \"Codebook did not load correctly\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73fd17f4-30e4-4826-ad34-6aac61432a9c",
   "metadata": {},
   "source": [
    "> Warning: get_ba_data uses a different way to remove b07 participants.  This should be adjusted to use the same function as get_phone_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9074c02-9a2d-4e5f-b223-b2ab34dc62b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "@get_efficiently\n",
    "def get_ba_data(self:DataProvider):\n",
    "    '''This function reads in baseline data from redcap, filters out pilot data, and creates movisens IDs.'''\n",
    "    df = pd.read_csv(self.ba_data_path)\n",
    "    df['center'] = df.groupby('participant_id').bx_center.transform(lambda x: x.ffill().bfill())\n",
    "    df['center'] = df.center.replace({1:'b',2:'d',3:'m'})\n",
    "    # Creating new movisense IDs (adding center prefix to movisense IDs)\n",
    "    for old_id in ['bx_movisens','bx_movisens_old','bx_movisens_old_2']:\n",
    "        new_id = old_id.replace('bx_','').replace('movisens','mov_id')\n",
    "        df[new_id] = df.groupby('participant_id')[old_id].transform(lambda x: x.ffill().bfill())\n",
    "        df[new_id] = df.center + df[new_id].astype('str').str.strip('0').str.strip('.').apply(lambda x: x.zfill(3))\n",
    "        df[new_id].fillna('nan',inplace = True)\n",
    "        df.loc[df[new_id].str.contains('nan'),new_id] = np.nan\n",
    "    # Removing test participants \n",
    "    remove = ['050744', 'hdfghadgfh', 'LindaEngel', 'test', 'Test001', 'Test001a', 'test0011', 'test0012', 'test0013', 'test0014', 'test0015', 'test002', 'test00229', 'test007', 'test01', 'test012', 'test013', 'test1', 'test2', 'test4', 'test12', 'test999', 'test2021', 'test345345', 'testneu', 'testtest', 'test_0720', 'test_10', 'test_GA', 'Test_JH','test0016','891752080', 'pipingTest', 'test0001', 'test00012', 'test0012a', 'test0015a', 'test0017', 'test10', 'test20212', 'testJohn01', 'test_00213', 'test_00233', 'test_00271', 'test_003', 'test_004', 'test_11_26', 'Test_MS','898922899', 'tesst', 'test0002', 'test0908', 'test092384750398475', 'test43', 'test123', 'test1233', 'test3425', 'test123456', 'test1234567', 'testfu3', 'test_888', 'test_999', 'test_98375983745', 'Test_Übung','050335', 'test003', 'test02', 'test111', 'test1111', 'test1234','test0000', 'test_CH']\n",
    "    df = df[~df.participant_id.astype(str).isin(remove)]\n",
    "    # Checking participant ids (to find new test participants)\n",
    "    bad_ids = df[~df.participant_id.apply(self.check_participant_id)].participant_id.unique()\n",
    "    assert len(bad_ids)==0, \"Bad participant IDs (should be added to remove): %s\"%', '.join([\"'%s'\"%b for b in bad_ids])\n",
    "    # labeling B07 participant\n",
    "    b07_pps = pd.read_excel(self.b07_participants_path)['Participant ID'].astype(str)\n",
    "    df['is_b07'] = False\n",
    "    df.loc[df.participant_id.isin(b07_pps),'is_b07'] = True\n",
    "    # Setting dtypes based on codebook\n",
    "    df = self.set_dtypes(df, self.get_ba_codebook())\n",
    "    # Creating convenience variables\n",
    "    df['is_female'] = df.screen_gender.replace({1:0,2:1,3:np.nan})\n",
    "    # Filling in missings from baseline\n",
    "    df['is_female'].fillna(df.bx_sozio_gender.replace({1:0,2:1,3:np.nan}), inplace = True)\n",
    "    df['is_female'] = df.groupby('participant_id')['is_female'].transform(lambda x: x.ffill().bfill())\n",
    "    df['is_female'] = df['is_female'].astype(float)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e09b8c7-dc87-47db-bb8f-7d66694f81eb",
   "metadata": {},
   "source": [
    "> ToDo: This should be defined as a \"slow test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179c1d1a-a695-4991-a220-14963b72dc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_ba = dp.get_ba_data()[['participant_id','redcap_event_name','redcap_repeat_instrument','redcap_repeat_instance']].value_counts().mean() == 1\n",
    "assert check_ba, \"Redcap BA data was not properly formatted\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91101dd2-403e-4bf9-9d1f-f3aa975ddfe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant_id</th>\n",
       "      <th>redcap_event_name</th>\n",
       "      <th>redcap_repeat_instrument</th>\n",
       "      <th>redcap_repeat_instance</th>\n",
       "      <th>redcap_survey_identifier</th>\n",
       "      <th>bx_pams</th>\n",
       "      <th>bx_exist120</th>\n",
       "      <th>study_id</th>\n",
       "      <th>bx_date</th>\n",
       "      <th>languages</th>\n",
       "      <th>...</th>\n",
       "      <th>bx_anruf_o2</th>\n",
       "      <th>bx_anruf_o2txt</th>\n",
       "      <th>bx_anruf_o3</th>\n",
       "      <th>anrufprotokoll_complete</th>\n",
       "      <th>center</th>\n",
       "      <th>mov_id</th>\n",
       "      <th>mov_id_old</th>\n",
       "      <th>mov_id_old_2</th>\n",
       "      <th>is_b07</th>\n",
       "      <th>is_female</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>53</td>\n",
       "      <td>erhebungszeitpunkt_arm_1</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10101.0</td>\n",
       "      <td>2021-10-20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>b</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53</td>\n",
       "      <td>mrterhebung_1_arm_1</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>b</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53</td>\n",
       "      <td>erhebungszeitpunkt_arm_1</td>\n",
       "      <td>at_home_qsu</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>b</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>erhebungszeitpunkt_arm_1</td>\n",
       "      <td>at_home_ftnd</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>b</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>53</td>\n",
       "      <td>erhebungszeitpunkt_arm_1</td>\n",
       "      <td>at_home_bis15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>b</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15010</th>\n",
       "      <td>12205</td>\n",
       "      <td>erhebungszeitpunkt_arm_1</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10101.0</td>\n",
       "      <td>2022-01-17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>m</td>\n",
       "      <td>m282</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15011</th>\n",
       "      <td>12205</td>\n",
       "      <td>mrterhebung_1_arm_1</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>m</td>\n",
       "      <td>m282</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15012</th>\n",
       "      <td>12205</td>\n",
       "      <td>mrterhebung_1_arm_1</td>\n",
       "      <td>neuerfb</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>m</td>\n",
       "      <td>m282</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15013</th>\n",
       "      <td>12205</td>\n",
       "      <td>mrterhebung_1_arm_1</td>\n",
       "      <td>clinic_participant_panas</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>m</td>\n",
       "      <td>m282</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15014</th>\n",
       "      <td>12205</td>\n",
       "      <td>mrterhebung_1_arm_1</td>\n",
       "      <td>clinic_examiner_mrt_examination</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>m</td>\n",
       "      <td>m282</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15015 rows × 3918 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      participant_id         redcap_event_name  \\\n",
       "0                 53  erhebungszeitpunkt_arm_1   \n",
       "1                 53       mrterhebung_1_arm_1   \n",
       "2                 53  erhebungszeitpunkt_arm_1   \n",
       "3                 53  erhebungszeitpunkt_arm_1   \n",
       "4                 53  erhebungszeitpunkt_arm_1   \n",
       "...              ...                       ...   \n",
       "15010          12205  erhebungszeitpunkt_arm_1   \n",
       "15011          12205       mrterhebung_1_arm_1   \n",
       "15012          12205       mrterhebung_1_arm_1   \n",
       "15013          12205       mrterhebung_1_arm_1   \n",
       "15014          12205       mrterhebung_1_arm_1   \n",
       "\n",
       "              redcap_repeat_instrument  redcap_repeat_instance  \\\n",
       "0                                 None                     NaN   \n",
       "1                                 None                     NaN   \n",
       "2                          at_home_qsu                     1.0   \n",
       "3                         at_home_ftnd                     1.0   \n",
       "4                        at_home_bis15                     1.0   \n",
       "...                                ...                     ...   \n",
       "15010                             None                     NaN   \n",
       "15011                             None                     NaN   \n",
       "15012                          neuerfb                     1.0   \n",
       "15013         clinic_participant_panas                     1.0   \n",
       "15014  clinic_examiner_mrt_examination                     1.0   \n",
       "\n",
       "       redcap_survey_identifier  bx_pams  bx_exist120 study_id    bx_date  \\\n",
       "0                           NaN      NaN          0.0  10101.0 2021-10-20   \n",
       "1                           NaN      NaN          NaN     None        NaT   \n",
       "2                           NaN      NaN          NaN     None        NaT   \n",
       "3                           NaN      NaN          NaN     None        NaT   \n",
       "4                           NaN      NaN          NaN     None        NaT   \n",
       "...                         ...      ...          ...      ...        ...   \n",
       "15010                       NaN      NaN          0.0  10101.0 2022-01-17   \n",
       "15011                       NaN      NaN          NaN     None        NaT   \n",
       "15012                       NaN      NaN          NaN     None        NaT   \n",
       "15013                       NaN      NaN          NaN     None        NaT   \n",
       "15014                       NaN      NaN          NaN     None        NaT   \n",
       "\n",
       "       languages  ...  bx_anruf_o2  bx_anruf_o2txt  bx_anruf_o3  \\\n",
       "0            NaN  ...          NaN             NaN          NaN   \n",
       "1            NaN  ...          NaN             NaN          NaN   \n",
       "2            NaN  ...          NaN             NaN          NaN   \n",
       "3            NaN  ...          NaN             NaN          NaN   \n",
       "4            NaN  ...          NaN             NaN          NaN   \n",
       "...          ...  ...          ...             ...          ...   \n",
       "15010        NaN  ...          NaN             NaN          NaN   \n",
       "15011        NaN  ...          NaN             NaN          NaN   \n",
       "15012        NaN  ...          NaN             NaN          NaN   \n",
       "15013        NaN  ...          NaN             NaN          NaN   \n",
       "15014        NaN  ...          NaN             NaN          NaN   \n",
       "\n",
       "      anrufprotokoll_complete  center  mov_id  mov_id_old  mov_id_old_2  \\\n",
       "0                         NaN       b    None        None          None   \n",
       "1                         NaN       b    None        None          None   \n",
       "2                         NaN       b    None        None          None   \n",
       "3                         NaN       b    None        None          None   \n",
       "4                         NaN       b    None        None          None   \n",
       "...                       ...     ...     ...         ...           ...   \n",
       "15010                     NaN       m    m282        None          None   \n",
       "15011                     NaN       m    m282        None          None   \n",
       "15012                     NaN       m    m282        None          None   \n",
       "15013                     NaN       m    m282        None          None   \n",
       "15014                     NaN       m    m282        None          None   \n",
       "\n",
       "       is_b07  is_female  \n",
       "0       False        0.0  \n",
       "1       False        0.0  \n",
       "2       False        0.0  \n",
       "3       False        0.0  \n",
       "4       False        0.0  \n",
       "...       ...        ...  \n",
       "15010   False        NaN  \n",
       "15011   False        NaN  \n",
       "15012   False        NaN  \n",
       "15013   False        NaN  \n",
       "15014   False        NaN  \n",
       "\n",
       "[15015 rows x 3918 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp.get_ba_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e013c5-9881-4495-a1af-37723d7afc96",
   "metadata": {},
   "source": [
    "### Getting standard drinks per day in last three months before baseline\n",
    "Used variables: \n",
    "- An wie vielen Tagen tranken Sie in den letzten 3 Monaten zumindest 1 Glas Alkohol? (bx_qf_alc_01)\n",
    "- Welches Format hatte die Angabe der Tage in der vorhergehenden Frage? (bx_qf_alc_02)\n",
    "  - Angabe in den letzten 3 Monaten. (1)\n",
    "  - Angabe pro Woche innerhalb der letzten 3 Monat. (2)\n",
    "- An diesen Tagen an denen Sie in den letzten 3 Monaten Alkohol tranken: Können Sie mir anhand der Abbildungen auf der Liste angeben, was und wie viel Sie üblicherweise an einem Tag tranken?\" (bx_qf1_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee87bed-aed4-490c-af45-e94bda9c7733",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant_id</th>\n",
       "      <th>redcap_event_name</th>\n",
       "      <th>mov_id</th>\n",
       "      <th>bx_qf_alc_01</th>\n",
       "      <th>bx_qf_alc_02</th>\n",
       "      <th>bx_qf1_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11367</th>\n",
       "      <td>11303</td>\n",
       "      <td>erhebungszeitpunkt_arm_1</td>\n",
       "      <td>m190</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11373</th>\n",
       "      <td>11303</td>\n",
       "      <td>erhebungszeitpunkt_arm_1</td>\n",
       "      <td>m190</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11374</th>\n",
       "      <td>11303</td>\n",
       "      <td>erhebungszeitpunkt_arm_1</td>\n",
       "      <td>m190</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11375</th>\n",
       "      <td>11303</td>\n",
       "      <td>erhebungszeitpunkt_arm_1</td>\n",
       "      <td>m190</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11376</th>\n",
       "      <td>11303</td>\n",
       "      <td>erhebungszeitpunkt_arm_1</td>\n",
       "      <td>m190</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11377</th>\n",
       "      <td>11303</td>\n",
       "      <td>erhebungszeitpunkt_arm_1</td>\n",
       "      <td>m190</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11378</th>\n",
       "      <td>11303</td>\n",
       "      <td>erhebungszeitpunkt_arm_1</td>\n",
       "      <td>m190</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11379</th>\n",
       "      <td>11303</td>\n",
       "      <td>erhebungszeitpunkt_arm_1</td>\n",
       "      <td>m190</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11380</th>\n",
       "      <td>11303</td>\n",
       "      <td>erhebungszeitpunkt_arm_1</td>\n",
       "      <td>m190</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11381</th>\n",
       "      <td>11303</td>\n",
       "      <td>erhebungszeitpunkt_arm_1</td>\n",
       "      <td>m190</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11382</th>\n",
       "      <td>11303</td>\n",
       "      <td>erhebungszeitpunkt_arm_1</td>\n",
       "      <td>m190</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11383</th>\n",
       "      <td>11303</td>\n",
       "      <td>erhebungszeitpunkt_arm_1</td>\n",
       "      <td>m190</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11384</th>\n",
       "      <td>11303</td>\n",
       "      <td>erhebungszeitpunkt_arm_1</td>\n",
       "      <td>m190</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11385</th>\n",
       "      <td>11303</td>\n",
       "      <td>erhebungszeitpunkt_arm_1</td>\n",
       "      <td>m190</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11386</th>\n",
       "      <td>11303</td>\n",
       "      <td>erhebungszeitpunkt_arm_1</td>\n",
       "      <td>m190</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11387</th>\n",
       "      <td>11303</td>\n",
       "      <td>erhebungszeitpunkt_arm_1</td>\n",
       "      <td>m190</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      participant_id         redcap_event_name mov_id bx_qf_alc_01  \\\n",
       "11367          11303  erhebungszeitpunkt_arm_1   m190         24.0   \n",
       "11373          11303  erhebungszeitpunkt_arm_1   m190         None   \n",
       "11374          11303  erhebungszeitpunkt_arm_1   m190         None   \n",
       "11375          11303  erhebungszeitpunkt_arm_1   m190         None   \n",
       "11376          11303  erhebungszeitpunkt_arm_1   m190         None   \n",
       "11377          11303  erhebungszeitpunkt_arm_1   m190         None   \n",
       "11378          11303  erhebungszeitpunkt_arm_1   m190         None   \n",
       "11379          11303  erhebungszeitpunkt_arm_1   m190         None   \n",
       "11380          11303  erhebungszeitpunkt_arm_1   m190         None   \n",
       "11381          11303  erhebungszeitpunkt_arm_1   m190         None   \n",
       "11382          11303  erhebungszeitpunkt_arm_1   m190         None   \n",
       "11383          11303  erhebungszeitpunkt_arm_1   m190         None   \n",
       "11384          11303  erhebungszeitpunkt_arm_1   m190         None   \n",
       "11385          11303  erhebungszeitpunkt_arm_1   m190         None   \n",
       "11386          11303  erhebungszeitpunkt_arm_1   m190         None   \n",
       "11387          11303  erhebungszeitpunkt_arm_1   m190         None   \n",
       "\n",
       "       bx_qf_alc_02  bx_qf1_sum  \n",
       "11367           1.0         3.2  \n",
       "11373           NaN         NaN  \n",
       "11374           NaN         NaN  \n",
       "11375           NaN         NaN  \n",
       "11376           NaN         NaN  \n",
       "11377           NaN         NaN  \n",
       "11378           NaN         NaN  \n",
       "11379           NaN         NaN  \n",
       "11380           NaN         NaN  \n",
       "11381           NaN         NaN  \n",
       "11382           NaN         NaN  \n",
       "11383           NaN         NaN  \n",
       "11384           NaN         NaN  \n",
       "11385           NaN         NaN  \n",
       "11386           NaN         NaN  \n",
       "11387           NaN         NaN  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ba = dp.get_ba_data(columns = ['participant_id','redcap_event_name','mov_id','bx_qf_alc_01','bx_qf_alc_02','bx_qf1_sum']).query(\"redcap_event_name=='erhebungszeitpunkt_arm_1'\")\n",
    "ba.loc[(ba.participant_id=='11303') & (ba.bx_qf_alc_02==2),'bx_qf_alc_02'] = 1\n",
    "ba.loc[(ba.participant_id=='11303')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5527a76-90e9-4770-83d7-ee42508cd1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def get_baseline_drinking_data(self:DataProvider):\n",
    "    # Getting relevant data\n",
    "    ba = self.get_ba_data(columns = ['participant_id','redcap_event_name','mov_id','bx_qf_alc_01','bx_qf_alc_02','bx_qf1_sum']).query(\"redcap_event_name=='erhebungszeitpunkt_arm_1'\")\n",
    "    # Correct one variable for one participant.  This participant reported drinking per three months but the data as logged as drinking per week\n",
    "    ba.loc[(ba.participant_id=='11303') & (ba.bx_qf_alc_02==2),'bx_qf_alc_02'] = 1\n",
    "    ba['drinking_days_last_three_month'] = ba['bx_qf_alc_01'].astype(float) * ba['bx_qf_alc_02'].replace({2:12})\n",
    "    ba['drinks_per_drinking_day_last_three_month'] = ba['bx_qf1_sum']\n",
    "    ba['drinks_per_day_last_three_month'] = (ba['drinking_days_last_three_month'] * ba['bx_qf1_sum'])/90\n",
    "    standard_last_three = ba[~ba.drinks_per_day_last_three_month.isnull()][['mov_id','drinks_per_day_last_three_month','drinks_per_drinking_day_last_three_month','drinking_days_last_three_month']]\n",
    "    standard_last_three.columns = ['participant','last_three_month','drinks_per_drinking_day_last_three_month','drinking_days_last_three_month']\n",
    "    standard_last_three = standard_last_three.groupby('participant').first()\n",
    "    return standard_last_three"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1b144d-8405-40a9-bec5-da28701428f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>last_three_month</th>\n",
       "      <th>drinks_per_drinking_day_last_three_month</th>\n",
       "      <th>drinking_days_last_three_month</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>participant</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>b000</th>\n",
       "      <td>5.666667</td>\n",
       "      <td>8.50</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b001</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>2.00</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b002</th>\n",
       "      <td>1.860000</td>\n",
       "      <td>4.65</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b012</th>\n",
       "      <td>2.880000</td>\n",
       "      <td>5.40</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b013</th>\n",
       "      <td>6.300000</td>\n",
       "      <td>6.75</td>\n",
       "      <td>84.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m278</th>\n",
       "      <td>1.653333</td>\n",
       "      <td>6.20</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m279</th>\n",
       "      <td>1.906667</td>\n",
       "      <td>7.15</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m280</th>\n",
       "      <td>1.240000</td>\n",
       "      <td>3.10</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m281</th>\n",
       "      <td>4.533333</td>\n",
       "      <td>8.50</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m282</th>\n",
       "      <td>2.200000</td>\n",
       "      <td>5.50</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>501 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             last_three_month  drinks_per_drinking_day_last_three_month  \\\n",
       "participant                                                               \n",
       "b000                 5.666667                                      8.50   \n",
       "b001                 0.800000                                      2.00   \n",
       "b002                 1.860000                                      4.65   \n",
       "b012                 2.880000                                      5.40   \n",
       "b013                 6.300000                                      6.75   \n",
       "...                       ...                                       ...   \n",
       "m278                 1.653333                                      6.20   \n",
       "m279                 1.906667                                      7.15   \n",
       "m280                 1.240000                                      3.10   \n",
       "m281                 4.533333                                      8.50   \n",
       "m282                 2.200000                                      5.50   \n",
       "\n",
       "             drinking_days_last_three_month  \n",
       "participant                                  \n",
       "b000                                   60.0  \n",
       "b001                                   36.0  \n",
       "b002                                   36.0  \n",
       "b012                                   48.0  \n",
       "b013                                   84.0  \n",
       "...                                     ...  \n",
       "m278                                   24.0  \n",
       "m279                                   24.0  \n",
       "m280                                   36.0  \n",
       "m281                                   48.0  \n",
       "m282                                   36.0  \n",
       "\n",
       "[501 rows x 3 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp.get_baseline_drinking_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4555c3-5739-48fb-a571-2f739d36e22c",
   "metadata": {},
   "source": [
    "### Getting Movisense data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc663495-183f-4847-8cef-8d775d11ecf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def get_duplicate_mov_ids(self:DataProvider):\n",
    "    '''This function creates a dictionary mapping old to new movisens IDs.'''\n",
    "    df = self.get_ba_data()\n",
    "    replace_dict_1 = dict(zip(df.mov_id_old, df.mov_id))\n",
    "    replace_dict_2 = dict(zip(df.mov_id_old_2, df.mov_id))\n",
    "    replace_dict = {**replace_dict_1, **replace_dict_2}\n",
    "    try:\n",
    "        del replace_dict[np.nan]\n",
    "    except:\n",
    "        pass\n",
    "    del replace_dict[None]\n",
    "    replace_dict['d033'] = 'd092' # This participant's data is currently missing in redcap, but they did change ID from 33 to 92\n",
    "    return replace_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23cd792-b3b8-45a6-8b7a-434df14bc357",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(dp.get_duplicate_mov_ids()), \"Could not load duplicate_mov_ids\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d73462-5c15-4b43-bbf7-d4d907186084",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "@get_efficiently\n",
    "def get_mov_data(self:DataProvider):\n",
    "    \"\"\"\n",
    "    This function gets Movisense data\n",
    "    1) We create unique participnat IDs (e.g. \"b001\"; this is necessary as sites use overapping IDs)\n",
    "    2) We merge double IDs, so participants with two IDs only have one (for this duplicate_ids.csv has to be updated)\n",
    "    3) We remove pilot participants\n",
    "    4) We get starting dates (from the participant overviews in movisense; downloaded as html)\n",
    "    5) We calculate sampling days and end dates based on the starting dates\n",
    "    \"\"\"\n",
    "    # Loading raw data\n",
    "    mov_berlin = pd.read_csv(self.mov_berlin_path, sep = ';')\n",
    "    mov_dresden = pd.read_csv(self.mov_dresden_path, sep = ';')\n",
    "    mov_mannheim = pd.read_csv(self.mov_mannheim_path, sep = ';')\n",
    "        \n",
    "    # Merging (participant numbers repeat so we add the first letter of location)\n",
    "    mov_berlin['location'] = 'berlin'\n",
    "    mov_dresden['location'] = 'dresden'\n",
    "    mov_mannheim['location'] = 'mannheim'\n",
    "    df = pd.concat([mov_berlin,mov_dresden,mov_mannheim])\n",
    "    df['participant'] =  df['location'].str[0] + df.Participant.apply(lambda x: '%03d'%int(x))\n",
    "    df.drop(columns = 'Participant', inplace = True) # Dropping old participant column to avoid mistakes\n",
    "    df['trigger_date'] = pd.to_datetime(df.Trigger_date + ' ' + df.Trigger_time)\n",
    "    \n",
    "    # Merging double IDs (for participants with several movisense IDs)\n",
    "    df['participant'] = df.participant.replace(self.get_duplicate_mov_ids())\n",
    "    \n",
    "    # Removing pilot participants\n",
    "    df = df[~df.participant.astype(str).str.contains('test')]\n",
    "    df = df[~df.participant.isin(['m157', 'b010', 'b006', 'd001', 'd002', 'd042', 'm024', 'm028', 'm071', 'm079', 'm107'])]\n",
    "    \n",
    "    \n",
    "    # Adding starting dates to get sampling days\n",
    "    def get_starting_dates(path, pp_prefix = ''):\n",
    "        soup = bs(open(path).read())\n",
    "        ids = [int(x.text) for x in soup.find_all(\"td\", class_ = 'simpleId')]\n",
    "        c_dates = [x.find_all(\"span\")[0]['title'] for x in soup.find_all(\"td\", class_ = 'coupleDate')]\n",
    "        s_dates = [x['value'] for x in soup.find_all(\"input\", class_ = 'dp startDate')]\n",
    "        df = pd.DataFrame({'participant':ids,'coupling_date':c_dates,'starting_date':s_dates})\n",
    "        df['coupling_date'] = pd.to_datetime(df.coupling_date)\n",
    "        df['starting_date'] = pd.to_datetime(df.starting_date)\n",
    "        df.starting_date.fillna(df.coupling_date,inplace = True)\n",
    "        df['participant'] = pp_prefix + df.participant.apply(lambda x: '%03d'%int(x))\n",
    "        return df\n",
    "    \n",
    "    starting_dates = pd.concat([\n",
    "    get_starting_dates(self.mov_berlin_starting_dates_path, 'b'),\n",
    "    get_starting_dates(self.mov_dresden_starting_dates_path, 'd'),\n",
    "    get_starting_dates(self.mov_mannheim_starting_dates_path, 'm')\n",
    "    ])\n",
    "    # For participants with several movisense IDs we use the first coupling date\n",
    "    starting_dates.participant.replace(self.get_duplicate_mov_ids(), inplace = True)\n",
    "    starting_dates = starting_dates.groupby('participant')[['starting_date','coupling_date']].min().reset_index()\n",
    "    df = df.merge(starting_dates, on=\"participant\", how = 'left', indicator = True)\n",
    "    # Checking if starting dates were downloaded\n",
    "    if \"left_only\" in df._merge.unique():\n",
    "        no_starting_dates = df.query('_merge == \"left_only\"').participant.unique()\n",
    "        print(\"Starting dates missing for participants below.  Did you download the participant overviews as html?\", no_starting_dates)\n",
    "    # Calculating movisense sampling day, adding date and end_date\n",
    "    df['sampling_day'] = (df['trigger_date'] - df['starting_date']).dt.days + 1\n",
    "    df['date'] = df.trigger_date.dt.date\n",
    "    df['end_date'] = df.date + pd.DateOffset(days = 365)\n",
    "    df.index.rename('mov_index',inplace = True)\n",
    "    # Adding redcap IDs\n",
    "    ids_table = self.get_ba_data()[['participant_id','mov_id']].query('mov_id==mov_id').groupby('mov_id').first()\n",
    "    ids_table.columns = ['redcap_id']\n",
    "    df = df.merge(ids_table, left_on='participant', right_index = True, how = 'left')\n",
    "    # Filtering out participants with no associated redcap data\n",
    "    no_redcap = df.query(\"redcap_id.isna()\").participant.unique()\n",
    "    print(\"Participants: %s have no associated redcap IDs and are excluded from the following analyses.\"%', '.join(no_redcap))\n",
    "    df = df[df.redcap_id.isna()==False]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2adfccdf-5b91-415b-ace9-db6cabdf0e3d",
   "metadata": {},
   "source": [
    "> Warning: Note that some participants do not have associated redcap data (see below).  These participants are excluded from further data analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09df4301-9a1e-446c-9ff0-49af129d765a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing mov_data\n",
      "Participants: b186, d092, m158 have no associated redcap IDs and are excluded from the following analyses.\n"
     ]
    }
   ],
   "source": [
    "_ = dp.get_mov_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84042155-2a65-4c4a-8f03-89f0cb6f364c",
   "metadata": {},
   "source": [
    "#### Structure of movisense data (selected columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bead81b8-c61a-47d8-a9a3-1dcf9381696e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant</th>\n",
       "      <th>starting_date</th>\n",
       "      <th>Trigger</th>\n",
       "      <th>Trigger_date</th>\n",
       "      <th>Trigger_counter</th>\n",
       "      <th>Form</th>\n",
       "      <th>INT_Coverage_kleinesBier</th>\n",
       "      <th>INT_Coverage_kleinerWeisswein</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mov_index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b001</td>\n",
       "      <td>2020-02-24</td>\n",
       "      <td>Button Pressed: Spiele starten und Initialfrag...</td>\n",
       "      <td>2020-02-24</td>\n",
       "      <td>9</td>\n",
       "      <td>Tag 1 Info</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b001</td>\n",
       "      <td>2020-02-24</td>\n",
       "      <td>Fixed Time: 09:00</td>\n",
       "      <td>2020-02-24</td>\n",
       "      <td>11</td>\n",
       "      <td>Missing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b001</td>\n",
       "      <td>2020-02-24</td>\n",
       "      <td>Fixed Time: 12:00</td>\n",
       "      <td>2020-02-24</td>\n",
       "      <td>17</td>\n",
       "      <td>Coverage</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b001</td>\n",
       "      <td>2020-02-24</td>\n",
       "      <td>Fixed Time: 12:00</td>\n",
       "      <td>2020-02-24</td>\n",
       "      <td>17</td>\n",
       "      <td>Craving</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b001</td>\n",
       "      <td>2020-02-24</td>\n",
       "      <td>Fixed Time: 12:00</td>\n",
       "      <td>2020-02-24</td>\n",
       "      <td>17</td>\n",
       "      <td>MDBF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200030</th>\n",
       "      <td>m235</td>\n",
       "      <td>2021-05-17</td>\n",
       "      <td>Button Pressed: Spiele starten und Initialfrag...</td>\n",
       "      <td>2021-08-16</td>\n",
       "      <td>16</td>\n",
       "      <td>Tag 1 Info</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200031</th>\n",
       "      <td>m235</td>\n",
       "      <td>2021-05-17</td>\n",
       "      <td>Button Pressed: Spiele starten und Initialfrag...</td>\n",
       "      <td>2021-08-16</td>\n",
       "      <td>16</td>\n",
       "      <td>Initial</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200032</th>\n",
       "      <td>m235</td>\n",
       "      <td>2021-05-17</td>\n",
       "      <td>Button Pressed: Spiele starten und Initialfrag...</td>\n",
       "      <td>2021-08-16</td>\n",
       "      <td>16</td>\n",
       "      <td>GBE_Tag1_Vorher</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200033</th>\n",
       "      <td>m235</td>\n",
       "      <td>2021-05-17</td>\n",
       "      <td>Button Pressed: Spiele starten und Initialfrag...</td>\n",
       "      <td>2021-08-16</td>\n",
       "      <td>16</td>\n",
       "      <td>GreatBrainExperiment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200034</th>\n",
       "      <td>m235</td>\n",
       "      <td>2021-05-17</td>\n",
       "      <td>Button Pressed: Spiele starten und Initialfrag...</td>\n",
       "      <td>2021-08-16</td>\n",
       "      <td>16</td>\n",
       "      <td>GreatBrainExperiment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>199456 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          participant starting_date  \\\n",
       "mov_index                             \n",
       "0                b001    2020-02-24   \n",
       "1                b001    2020-02-24   \n",
       "2                b001    2020-02-24   \n",
       "3                b001    2020-02-24   \n",
       "4                b001    2020-02-24   \n",
       "...               ...           ...   \n",
       "200030           m235    2021-05-17   \n",
       "200031           m235    2021-05-17   \n",
       "200032           m235    2021-05-17   \n",
       "200033           m235    2021-05-17   \n",
       "200034           m235    2021-05-17   \n",
       "\n",
       "                                                     Trigger Trigger_date  \\\n",
       "mov_index                                                                   \n",
       "0          Button Pressed: Spiele starten und Initialfrag...   2020-02-24   \n",
       "1                                          Fixed Time: 09:00   2020-02-24   \n",
       "2                                          Fixed Time: 12:00   2020-02-24   \n",
       "3                                          Fixed Time: 12:00   2020-02-24   \n",
       "4                                          Fixed Time: 12:00   2020-02-24   \n",
       "...                                                      ...          ...   \n",
       "200030     Button Pressed: Spiele starten und Initialfrag...   2021-08-16   \n",
       "200031     Button Pressed: Spiele starten und Initialfrag...   2021-08-16   \n",
       "200032     Button Pressed: Spiele starten und Initialfrag...   2021-08-16   \n",
       "200033     Button Pressed: Spiele starten und Initialfrag...   2021-08-16   \n",
       "200034     Button Pressed: Spiele starten und Initialfrag...   2021-08-16   \n",
       "\n",
       "           Trigger_counter                  Form  INT_Coverage_kleinesBier  \\\n",
       "mov_index                                                                    \n",
       "0                        9            Tag 1 Info                       NaN   \n",
       "1                       11               Missing                       NaN   \n",
       "2                       17              Coverage                       NaN   \n",
       "3                       17               Craving                       NaN   \n",
       "4                       17                  MDBF                       NaN   \n",
       "...                    ...                   ...                       ...   \n",
       "200030                  16            Tag 1 Info                       NaN   \n",
       "200031                  16               Initial                       NaN   \n",
       "200032                  16       GBE_Tag1_Vorher                       NaN   \n",
       "200033                  16  GreatBrainExperiment                       NaN   \n",
       "200034                  16  GreatBrainExperiment                       NaN   \n",
       "\n",
       "           INT_Coverage_kleinerWeisswein  \n",
       "mov_index                                 \n",
       "0                                    NaN  \n",
       "1                                    NaN  \n",
       "2                                    NaN  \n",
       "3                                    NaN  \n",
       "4                                    NaN  \n",
       "...                                  ...  \n",
       "200030                               NaN  \n",
       "200031                               NaN  \n",
       "200032                               NaN  \n",
       "200033                               NaN  \n",
       "200034                               NaN  \n",
       "\n",
       "[199456 rows x 8 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp.get_mov_data()[['participant','starting_date','Trigger','Trigger_date','Trigger_counter','Form','INT_Coverage_kleinesBier','INT_Coverage_kleinerWeisswein']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e879a497-d136-47b9-9e9e-f0e6cdc32784",
   "metadata": {},
   "source": [
    "### Getting two-day data\n",
    "This is a subset of the movisense data (only the two-daily questions), which we reformat so that each day is one one line.  We also add nan data for dates after the last data was received until 365 days until the starting date.  We rearrange answers to retrospective questions, so they are associated with the date in question rather than the date on which the question was answered.  For example, the answer to the question \"How many beers did you drink two days ago\" gets shifted two days back from the date of the question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29cf8fc8-19ef-4a19-8995-da79547a61ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def get_alcohol_per_drink(self:DataProvider):\n",
    "    if not os.path.isfile(self.alcohol_per_drink_path):\n",
    "        return None\n",
    "    else:\n",
    "        return pd.read_csv(self.alcohol_per_drink_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9773301-5f61-4758-a783-0e09e5539e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert type(dp.get_alcohol_per_drink()) == type(pd.DataFrame()), \"Could not load 'alcohol_per_drink.csv' from external data\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f775443f-b587-4ab0-9392-011b876df0ec",
   "metadata": {},
   "source": [
    "> We use this conversion table to convert participants' answers into ml_alc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2515ff5-5366-4b6c-ab96-1dcac8d9ba6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>amount</th>\n",
       "      <th>unit</th>\n",
       "      <th>vol</th>\n",
       "      <th>ml_alc_per_drink</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kleines Bier</td>\n",
       "      <td>0.20</td>\n",
       "      <td>Liter</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mittleres Bier</td>\n",
       "      <td>0.33</td>\n",
       "      <td>Liter</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Großes Bier</td>\n",
       "      <td>0.50</td>\n",
       "      <td>Liter</td>\n",
       "      <td>5.0</td>\n",
       "      <td>25.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kleiner Weißwein</td>\n",
       "      <td>0.10</td>\n",
       "      <td>Liter</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mittlerer Weißwein</td>\n",
       "      <td>0.20</td>\n",
       "      <td>Liter</td>\n",
       "      <td>11.0</td>\n",
       "      <td>22.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Flasche Weißwein</td>\n",
       "      <td>0.75</td>\n",
       "      <td>Liter</td>\n",
       "      <td>11.0</td>\n",
       "      <td>82.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Kleiner Rotwein</td>\n",
       "      <td>0.10</td>\n",
       "      <td>Liter</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Mittlerer Rotwein</td>\n",
       "      <td>0.20</td>\n",
       "      <td>Liter</td>\n",
       "      <td>12.0</td>\n",
       "      <td>24.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Flasche Rotwein</td>\n",
       "      <td>0.75</td>\n",
       "      <td>Liter</td>\n",
       "      <td>12.0</td>\n",
       "      <td>90.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sekt</td>\n",
       "      <td>0.10</td>\n",
       "      <td>Liter</td>\n",
       "      <td>11.5</td>\n",
       "      <td>11.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Flasche Sekt</td>\n",
       "      <td>0.75</td>\n",
       "      <td>Liter</td>\n",
       "      <td>11.5</td>\n",
       "      <td>86.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Likör-Wein</td>\n",
       "      <td>5.00</td>\n",
       "      <td>cl</td>\n",
       "      <td>19.7</td>\n",
       "      <td>9.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Kleiner Likör</td>\n",
       "      <td>2.00</td>\n",
       "      <td>cl</td>\n",
       "      <td>20.0</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Großer Likör</td>\n",
       "      <td>5.00</td>\n",
       "      <td>cl</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Likör süß</td>\n",
       "      <td>2.00</td>\n",
       "      <td>cl</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Kleine Spirituose</td>\n",
       "      <td>2.00</td>\n",
       "      <td>cl</td>\n",
       "      <td>40.0</td>\n",
       "      <td>8.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Große Spirituose</td>\n",
       "      <td>5.00</td>\n",
       "      <td>cl</td>\n",
       "      <td>40.0</td>\n",
       "      <td>20.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Spirituose</td>\n",
       "      <td>100.00</td>\n",
       "      <td>ml</td>\n",
       "      <td>40.0</td>\n",
       "      <td>40.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Kleine Spirituose</td>\n",
       "      <td>2.00</td>\n",
       "      <td>cl</td>\n",
       "      <td>65.0</td>\n",
       "      <td>13.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  name  amount   unit   vol  ml_alc_per_drink\n",
       "0         Kleines Bier    0.20  Liter   5.0             10.00\n",
       "1       Mittleres Bier    0.33  Liter   5.0             16.50\n",
       "2          Großes Bier    0.50  Liter   5.0             25.00\n",
       "3     Kleiner Weißwein    0.10  Liter  11.0             11.00\n",
       "4   Mittlerer Weißwein    0.20  Liter  11.0             22.00\n",
       "5     Flasche Weißwein    0.75  Liter  11.0             82.50\n",
       "6      Kleiner Rotwein    0.10  Liter  12.0             12.00\n",
       "7    Mittlerer Rotwein    0.20  Liter  12.0             24.00\n",
       "8      Flasche Rotwein    0.75  Liter  12.0             90.00\n",
       "9                 Sekt    0.10  Liter  11.5             11.50\n",
       "10        Flasche Sekt    0.75  Liter  11.5             86.25\n",
       "11         Likör-Wein     5.00     cl  19.7              9.85\n",
       "12      Kleiner Likör     2.00     cl  20.0              4.00\n",
       "13       Großer Likör     5.00     cl  20.0             10.00\n",
       "14          Likör süß     2.00     cl  17.0              3.40\n",
       "15  Kleine Spirituose     2.00     cl  40.0              8.00\n",
       "16   Große Spirituose     5.00     cl  40.0             20.00\n",
       "17         Spirituose   100.00     ml  40.0             40.00\n",
       "18  Kleine Spirituose     2.00     cl  65.0             13.00"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp.get_alcohol_per_drink()[['name','amount','unit','vol','ml_alc_per_drink']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2824683-9fa8-4ce7-803b-e82907a4493d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "@get_efficiently\n",
    "def get_two_day_data(self:DataProvider):\n",
    "    \"\"\"Gets two-day which are a subset of mov_data\n",
    "    1) We select two-day forms and turn the dataframe into one row per participant-date (Form repetitions on the same day are removed)\n",
    "    2) We reduce all drinking questions to an easily readable dictionary of drink amounts.\n",
    "    3) We add missing data for dates on which we did not receive answers (starting 2 days before starting date up to 365 days after)\n",
    "    4) We shift answers from retrospective drinking questions backwards to the adequate date (e.g. one day back for yesterday questions) \n",
    "    \"\"\"\n",
    "    mov_data = self.get_mov_data().reset_index()\n",
    "    drinking_columns = [c for c in mov_data.columns if c.startswith(\"Anzahl\") and \"10day\" not in c]\n",
    "    mdbf_columns = [c for c in mov_data.columns if \"MDBF\" in c and \"INT\" not in c]\n",
    "    two_day_columns = ['mov_index','starting_date','end_date','sampling_day'] + drinking_columns + mdbf_columns + ['soziale_isolation','alternative_rewards','craving','Limit','Kontrolle']\n",
    "    # 1) Turning df into one line per date\n",
    "    two_day_forms = [\"Coverage\",\"Soziale Isolation\",\"Craving\",\"MDBF\",\"Alternative Rewards\",\"Limits & Control\"]\n",
    "    df = mov_data.sort_values(by=['participant','trigger_date','Form','Trigger_counter'])\n",
    "    df = df[df.Form.isin(two_day_forms)].groupby([\"participant\",\"date\"])[two_day_columns].first().dropna(how='all').reset_index()\n",
    "    # 2) Turning drinking answers into dictionaries\n",
    "    df[drinking_columns].fillna(0,inplace = True)\n",
    "    df['drinks_gestern'] = df[[c for c in drinking_columns if \"vorgestern\" not in c]].fillna(0).agg(lambda x: x.to_dict(), axis=1)\n",
    "    df['drinks_vorgestern'] = df[[c for c in drinking_columns if \"vorgestern\" in c]].fillna(0).agg(lambda x: x.to_dict(), axis=1)\n",
    "    # Adding missing values\n",
    "    def add_missing_data(df):\n",
    "        dates = pd.date_range(df.starting_date.iloc[0]-pd.DateOffset(days = 2), df.end_date.iloc[0])\n",
    "        df = df.reindex(dates)\n",
    "        df.index.names = ['date']\n",
    "        df[['starting_date','sampling_day']] = df[['starting_date','sampling_day']].bfill().ffill()\n",
    "        return df\n",
    "    df = df.set_index('date').groupby('participant').apply(add_missing_data).drop(columns='participant').reset_index()\n",
    "    \n",
    "    # 3) Shifting back retrospective answers\n",
    "    df['drinks'] = df['drinks_gestern'].shift(-1) # Drinks yesterday get shifted back one day\n",
    "    df['drinks'].fillna(df['drinks_vorgestern'].shift(-2), inplace = True) # Drinks before yesterday shift back two days\n",
    "    df['limit'] = df.Limit.ffill(limit=8) # Limit gets repeated forward for eight days\n",
    "    df['control'] = df.Kontrolle.bfill(limit=8) # Control is repeated backward for eight days\n",
    "    # 4) Calculating daily alcohol consumption in grams\n",
    "    alc_dict = {\"Anzahl\"+k:v for k,v in self.get_alcohol_per_drink().set_index('drink')['ml_alc_per_drink'].to_dict().items()}\n",
    "    def calculate_g_alc(x):\n",
    "        if x != x:\n",
    "            ml_alc = np.nan\n",
    "        else:\n",
    "            ml_alc = 0\n",
    "            for k,v in x.items():\n",
    "                if v > 0:\n",
    "                    ml_alc += alc_dict[k.split('_')[0]] * v\n",
    "        return ml_alc * .8\n",
    "    df['g_alc']  = df.drinks.apply(calculate_g_alc)\n",
    "    # Returning relevant columns only\n",
    "    df = df.reset_index()\n",
    "    df['sampling_day'] = df.groupby('participant').starting_date.cumcount() + 1\n",
    "    df.index.rename('two_day_index',inplace = True)\n",
    "    return df[['mov_index','participant','starting_date','date','sampling_day'] + mdbf_columns + ['soziale_isolation','alternative_rewards','craving','limit','control','drinks','g_alc']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1fe22d-f69d-448f-98ab-863e0dfa1059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing two_day_data\n"
     ]
    }
   ],
   "source": [
    "_ = dp.get_two_day_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89993eaf-aa86-4b25-9d87-b1a63d5cacca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_one_line_per_participant_day():\n",
    "    return dp.get_two_day_data().groupby(['participant','date']).date.count().value_counts().index[0] == 1\n",
    "\n",
    "assert test_one_line_per_participant_day(), \"Two day data does not have one line per participant day.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c63c32-af1a-48f1-b0be-a94f62793e2c",
   "metadata": {},
   "source": [
    "#### Structure of two-day data\n",
    "> Warning: Note that sampling days run further than 365.  This should not be the case.  It turns out that for these participants the end date was manually set further than one year after the start date, on the movisens page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1782c327-cd94-4f14-a760-aab316661347",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mov_index</th>\n",
       "      <th>participant</th>\n",
       "      <th>date</th>\n",
       "      <th>starting_date</th>\n",
       "      <th>sampling_day</th>\n",
       "      <th>soziale_isolation</th>\n",
       "      <th>drinks</th>\n",
       "      <th>g_alc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>two_day_index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>b001</td>\n",
       "      <td>2020-02-22</td>\n",
       "      <td>2020-02-24</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'AnzahlFlascheWeisswein': None, 'AnzahlFlasch...</td>\n",
       "      <td>6.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>b001</td>\n",
       "      <td>2020-02-23</td>\n",
       "      <td>2020-02-24</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'AnzahlFlascheWeisswein': 0.0, 'AnzahlFlasche...</td>\n",
       "      <td>35.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.0</td>\n",
       "      <td>b001</td>\n",
       "      <td>2020-02-24</td>\n",
       "      <td>2020-02-24</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>b001</td>\n",
       "      <td>2020-02-25</td>\n",
       "      <td>2020-02-24</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>b001</td>\n",
       "      <td>2020-02-26</td>\n",
       "      <td>2020-02-24</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134247</th>\n",
       "      <td>NaN</td>\n",
       "      <td>m271</td>\n",
       "      <td>2021-12-10</td>\n",
       "      <td>2020-12-14</td>\n",
       "      <td>364</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134248</th>\n",
       "      <td>NaN</td>\n",
       "      <td>m271</td>\n",
       "      <td>2021-12-11</td>\n",
       "      <td>2020-12-14</td>\n",
       "      <td>365</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134249</th>\n",
       "      <td>NaN</td>\n",
       "      <td>m271</td>\n",
       "      <td>2021-12-12</td>\n",
       "      <td>2020-12-14</td>\n",
       "      <td>366</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134250</th>\n",
       "      <td>NaN</td>\n",
       "      <td>m271</td>\n",
       "      <td>2021-12-13</td>\n",
       "      <td>2020-12-14</td>\n",
       "      <td>367</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134251</th>\n",
       "      <td>NaN</td>\n",
       "      <td>m271</td>\n",
       "      <td>2021-12-14</td>\n",
       "      <td>2020-12-14</td>\n",
       "      <td>368</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>134252 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               mov_index participant       date starting_date  sampling_day  \\\n",
       "two_day_index                                                                 \n",
       "0                    NaN        b001 2020-02-22    2020-02-24             1   \n",
       "1                    NaN        b001 2020-02-23    2020-02-24             2   \n",
       "2                    6.0        b001 2020-02-24    2020-02-24             3   \n",
       "3                    NaN        b001 2020-02-25    2020-02-24             4   \n",
       "4                    NaN        b001 2020-02-26    2020-02-24             5   \n",
       "...                  ...         ...        ...           ...           ...   \n",
       "134247               NaN        m271 2021-12-10    2020-12-14           364   \n",
       "134248               NaN        m271 2021-12-11    2020-12-14           365   \n",
       "134249               NaN        m271 2021-12-12    2020-12-14           366   \n",
       "134250               NaN        m271 2021-12-13    2020-12-14           367   \n",
       "134251               NaN        m271 2021-12-14    2020-12-14           368   \n",
       "\n",
       "               soziale_isolation  \\\n",
       "two_day_index                      \n",
       "0                            NaN   \n",
       "1                            NaN   \n",
       "2                            1.0   \n",
       "3                            NaN   \n",
       "4                            NaN   \n",
       "...                          ...   \n",
       "134247                       NaN   \n",
       "134248                       NaN   \n",
       "134249                       NaN   \n",
       "134250                       NaN   \n",
       "134251                       NaN   \n",
       "\n",
       "                                                          drinks  g_alc  \n",
       "two_day_index                                                            \n",
       "0              {'AnzahlFlascheWeisswein': None, 'AnzahlFlasch...    6.4  \n",
       "1              {'AnzahlFlascheWeisswein': 0.0, 'AnzahlFlasche...   35.2  \n",
       "2                                                           None    NaN  \n",
       "3                                                           None    NaN  \n",
       "4                                                           None    NaN  \n",
       "...                                                          ...    ...  \n",
       "134247                                                      None    NaN  \n",
       "134248                                                      None    NaN  \n",
       "134249                                                      None    NaN  \n",
       "134250                                                      None    NaN  \n",
       "134251                                                      None    NaN  \n",
       "\n",
       "[134252 rows x 8 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp.get_two_day_data()[['mov_index','participant','date','starting_date','sampling_day','soziale_isolation','drinks','g_alc']]#.iloc[:20]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
