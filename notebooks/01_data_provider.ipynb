{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c29c9ff-5273-4bd1-9952-b1ef8a7c8d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp data_provider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82658e0-1f45-4e64-9b6e-9090f8508fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8955535-3f82-4a44-bd5e-1588c7338cfd",
   "metadata": {},
   "source": [
    "# Data Provider\n",
    "\n",
    "> This module is responsible for processing raw TRR data for further analysis. ToDo: This code should be formatted as a class that gets the data folder path on init."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada8fe42-eee8-4938-b729-897c1d50412e",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b870468e-b220-4667-89a0-40fb3d2c1a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_data_folder():\n",
    "    return '/Users/hilmarzech/Projects/trr265/trr265/data/'\n",
    "    #return dotenv.dotenv_values()['DATA_FOLDER_PATH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe0bdab-f4ca-454e-9a23-1b6461021e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert os.path.isdir(get_data_folder()), \"Main data folder not found.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eaa8563-0473-446e-b933-6c5a73deb169",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_raw():\n",
    "    return os.path.join(get_data_folder(), 'raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169cdc2f-2f14-443c-ad45-19092221d6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert os.path.isdir(get_raw()), \"Raw data folder not found.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2af14e-093b-4be6-9f52-a441a1edfad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_external():\n",
    "    return os.path.join(get_data_folder(), 'external')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3d2b25-a414-4cf3-ad35-62cc2b7468f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert os.path.isdir(get_external()), \"External data folder not found.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4cb81b-07e2-4079-be27-2737522c37f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_interim():\n",
    "    return os.path.join(get_data_folder(), 'interim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3a3a17-074d-42bb-9d5a-c52fde4545e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert os.path.isdir(get_interim()), \"Interim data folder not found.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c666d947-5111-4652-ade2-58a396b8741f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_processed():\n",
    "    return os.path.join(get_data_folder(), 'processed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fe0e85-174f-4e94-bac0-523defd99c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert os.path.isdir(get_processed()), \"Processed data folder not found.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535486b2-de7d-4192-b373-16b7f37db73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def store_interim(df, filename):\n",
    "    path = os.path.join(get_interim(),\"%s.parquet\"%filename)\n",
    "    df.to_parquet(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a25773-9237-4cd7-a8ed-ab3707374728",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export    \n",
    "def load_interim(filename):\n",
    "    return pd.read_parquet(os.path.join(get_interim(),\"%s.parquet\"%filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41947b40-f87c-4f37-8afb-e16350a4c75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def storing_test():\n",
    "    df = pd.DataFrame({\"test\":[4]})\n",
    "    # Storing the dataframe\n",
    "    store_interim(df, 'storing_test')\n",
    "    # Reloading it and comparing to original\n",
    "    return df.equals(load_interim('storing_test'))\n",
    "assert storing_test(), \"Data storage is failing.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6d1303-92fc-4296-a712-1b3cc28396e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_efficiently(func):\n",
    "    \"\"\"\n",
    "    This decorator wraps around functions that get data and handles data storage.\n",
    "    If the output from the function hasn't been stored yet, it stores it in a .parquet file\n",
    "    If the output from the function has been stored already, it loads the stored file instead of running the function (unless update is specified as True)\n",
    "    \"\"\"\n",
    "    def wrapper(update = False, columns = None, *args, **kw):\n",
    "        var_name = func.__name__.replace('get_','')\n",
    "        file_path = os.path.join(get_interim(), \"%s.parquet\"%var_name)\n",
    "        if os.path.exists(file_path) and (update == False):\n",
    "            result =  pd.read_parquet(file_path, columns = columns)\n",
    "        else:\n",
    "            print(\"Preparing %s\"%var_name)\n",
    "            result = func()\n",
    "            result.to_parquet(file_path)\n",
    "        return result\n",
    "    w = wrapper\n",
    "    w.__wrapped__ = func # Specifying the wrapped function for inspection\n",
    "    w.__doc__ = func.__doc__\n",
    "    return w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba56b438-5e7e-48e8-9b5b-1f034d5f094b",
   "metadata": {},
   "source": [
    "### Getting phone screening data\n",
    "> ToDo: The hardcoded file paths should be made relative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d1e417-f33e-496a-a00a-709b566bc386",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_phone_codebook():\n",
    "    tables = pd.read_html(open('../data/raw/phone_codebook.html','r').read())\n",
    "    df = tables[1]\n",
    "    # Note that str.contains fills NaN values with nan, which can lead to strange results during filtering\n",
    "    df = df[df.LabelHinweistext.str.contains('Fragebogen:',na=False)==False]\n",
    "    df = df.set_index('#')\n",
    "    # Parsing variable name\n",
    "    df['variable'] = df[\"Variable / Feldname\"].apply(lambda x: x.split(' ')[0])\n",
    "    # Parsing condition under which variable is displayed\n",
    "    df['condition'] = df[\"Variable / Feldname\"].apply(lambda x: ' '.join(x.split(' ')[1:]).strip() if len(x.split(' '))>1 else '')\n",
    "    df['condition'] = df.condition.apply(lambda x: x.replace('Zeige das Feld nur wenn:  ',''))\n",
    "    # Parsing labels for numerical data\n",
    "    df['labels'] = np.nan\n",
    "    labels = tables[2:-1]\n",
    "    try:\n",
    "        labels = [dict(zip(l[0],l[1])) for l in labels]\n",
    "    except:\n",
    "        display(table)\n",
    "    searchfor = [\"radio\",\"dropdown\",\"yesno\",\"checkbox\"]\n",
    "    with_table = df['Feld Attribute (Feld-Typ, Prüfung, Auswahlen, Verzweigungslogik, Berechnungen, usw.)'].str.contains('|'.join(searchfor))\n",
    "    df.loc[with_table,'labels'] = labels\n",
    "    df = df.astype(str)\n",
    "    return df\n",
    "\n",
    "#export\n",
    "def determine_phone_b07(df):\n",
    "    # Some initial fixes\n",
    "    df.loc[df.center=='d','screen_caller'] = df.loc[df.center=='d','screen_caller'].str.lower().str.strip().replace('leo','leonard visser').replace('sebastian mörcke','sebastian möricke').replace('jessica zimmerman','jessica zimmermann').replace('miriam-sophie petasch','miriam petasch').replace('dorothee','dorothee scheuermann')\n",
    "    # Cleaning screener list\n",
    "    dd_screeners = df[(df.center=='d')&(df.screen_caller.isna()==False)].screen_caller.unique()\n",
    "    def clean_screeners(dd_screeners):\n",
    "        dd_screeners = [y  for x in dd_screeners for y in x.split('+')]\n",
    "        dd_screeners = [y  for x in dd_screeners for y in x.split(',')]\n",
    "        dd_screeners = [y  for x in dd_screeners for y in x.split('und')]\n",
    "        dd_screeners = [y.replace('(15.02.21)','')  for x in dd_screeners for y in x.split('/')]\n",
    "        dd_screeners = [y.replace(')','').strip().lower()  for x in dd_screeners for y in x.split('(')]\n",
    "        dd_screeners = sorted(list(set(dd_screeners)))\n",
    "        return dd_screeners\n",
    "    dd_screeners = clean_screeners(dd_screeners)\n",
    "    \n",
    "    b07_screeners = ['ann-kathrin stock','charlotte blum','josephine kirschgens','klara macht','borchardt','marta ledro','miriam petasch','mona hofmann','theo tester']\n",
    "    s01_screeners = ['esther preuschhof', 'miriam schmitz', 'sebastian möricke', 'jessica zimmermann', 'leonard visser', 'anna-lena lünert', 'anne dörfler', 'dominic reichert', 'maike borchardt', 'dorothee scheuermann', 'paula böhlmann', 'alice']\n",
    "    known_dd_screeners = list(b07_screeners+s01_screeners)\n",
    "    dd_screeners = df[(df.center=='d')&(df.screen_caller.isna()==False)].screen_caller.unique()\n",
    "    # Checking if all Dresden phone screeners are accounted for\n",
    "    assert df[(df.center=='d')&(df.screen_caller)].screen_caller.str.contains('|'.join(known_dd_screeners)).mean()==1, \"Unknown Dresden phone screener: %s\"%', '.join(set(clean_screeners(dd_screeners))-set(known_dd_screeners))\n",
    "    # In general, if a screener from a project was involved, it was screened for that project\n",
    "    df['screened_for_b07'] = (df.center=='d') & (df.screen_caller.str.contains('|'.join(b07_screeners)))\n",
    "    df['screened_for_s01'] = (df.center!='d') | (df.screen_caller.str.contains('|'.join(s01_screeners)))\n",
    "    \n",
    "    # We also exclude participants screened for C02 in Berlin\n",
    "    df.loc[(df.screen_purpose == 4) & (df.center=='b'), 'screened_for_s01'] = False\n",
    "    \n",
    "    # Additionally, we also set it to true if it was specifically set\n",
    "    df.loc[df.screen_site_dd == 1, 'screened_for_s01'] = True\n",
    "    df.loc[df.screen_site_dd == 3, 'screened_for_s01'] = True\n",
    "    df.loc[df.screen_site_dd == 2, 'screened_for_b07'] = True\n",
    "    df.loc[df.screen_site_dd == 3, 'screened_for_b07'] = True\n",
    "    return df\n",
    "\n",
    "#export\n",
    "def load_phone_data():\n",
    "    df = pd.read_csv('../data/raw/phonescreening.csv',\n",
    "                     na_values = [\"A 'MySQL server has gone away' error was detected.  It is possible that there was an actual database issue, but it is more likely that REDCap detected this request as a duplicate and killed it.\"]\n",
    "                    )\n",
    "    remove = ['050571', '307493', '345678', '715736', 'Ihloff', 'test',\n",
    "       'test002', 'test003', 'test004', 'test005', 'test01', 'test02',\n",
    "       'test03', 'test0722', 'test1', 'test34', 'test999', 'test2020',\n",
    "       'test20201', 'test345345', 'testt', 'test_10', 'test_11_26',\n",
    "       'test_neu', 'xx956']\n",
    "    df = df[~df.participant_id.astype(str).isin(remove)]\n",
    "    bad_ids = df[~df.participant_id.apply(check_participant_id)].participant_id.unique()\n",
    "    assert len(bad_ids)==0, \"Bad participant IDs (should be added to remove): %s\"%', '.join([\"'%s'\"%b for b in bad_ids])\n",
    "    df = set_dtypes(df, get_phone_codebook())\n",
    "    df['participant_id'] = df.participant_id.astype(int)\n",
    "    df['center'] = df.screen_site.replace({1:'b',2:'d',3:'m'})\n",
    "    df['screen_date'] = pd.to_datetime(df['screen_date'], errors = 'coerce')\n",
    "    #display(df[df.screen_caller.isna()])\n",
    "    df = determine_phone_b07(df)    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a2d1da-ddd7-49e4-a6fe-5d6c293a3ca0",
   "metadata": {},
   "source": [
    "### Getting baseline data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05057e7-c649-42cb-8d67-f82e362a1ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def check_participant_id(x):\n",
    "    '''This function checks whether a participant ID is numerical and lower than 20000.'''\n",
    "    if str(x) == x:\n",
    "        if x.isnumeric():\n",
    "            x = float(x)\n",
    "        else:\n",
    "            return False\n",
    "    if x > 20000:\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b55b88-476d-4826-b174-03ca39d1c76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_check_participant_id():\n",
    "    failed = check_participant_id('test10') == False # Example of a bad participant ID\n",
    "    passed = check_participant_id('100') == True # Example of a good participant ID\n",
    "    return failed and passed\n",
    "    \n",
    "assert test_check_participant_id(), \"Participant ID check is not working\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6646b911-a932-4f9a-b188-261c072a610c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@get_efficiently\n",
    "def get_ba_codebook():\n",
    "    tables = pd.read_html(open(os.path.join(get_external(), \"ba_codebook.html\"),\"r\").read())\n",
    "    df = tables[1]\n",
    "    # Note that str.contains fills NaN values with nan, which can lead to strange results during filtering\n",
    "    df = df[df.LabelHinweistext.str.contains('Fragebogen:',na=False)==False]\n",
    "    df = df.set_index('#')\n",
    "    # Parsing variable name\n",
    "    df['variable'] = df[\"Variable / Feldname\"].apply(lambda x: x.split(' ')[0])\n",
    "    # Parsing condition under which variable is displayed\n",
    "    df['condition'] = df[\"Variable / Feldname\"].apply(lambda x: ' '.join(x.split(' ')[1:]).strip() if len(x.split(' '))>1 else '')\n",
    "    df['condition'] = df.condition.apply(lambda x: x.replace('Zeige das Feld nur wenn:  ',''))\n",
    "    # Parsing labels for numerical data\n",
    "    df['labels'] = np.nan\n",
    "    labels = tables[2:-1]\n",
    "    try:\n",
    "        labels = [dict(zip(l[0],l[1])) for l in labels]\n",
    "    except:\n",
    "        display(table)\n",
    "    searchfor = [\"radio\",\"dropdown\",\"yesno\",\"checkbox\"]\n",
    "    with_table = df['Feld Attribute (Feld-Typ, Prüfung, Auswahlen, Verzweigungslogik, Berechnungen, usw.)'].str.contains('|'.join(searchfor))\n",
    "    df.loc[with_table,'labels'] = labels\n",
    "    df = df.astype(str)\n",
    "    return df\n",
    "\n",
    "assert 'variable' in get_ba_codebook().columns, \"Codebook did not load correctly\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96239a5-3857-4485-a0ca-488696352058",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def set_dtypes(data, codebook):\n",
    "    # Parsing type\n",
    "    codebook['type'] = codebook[\"Feld Attribute (Feld-Typ, Prüfung, Auswahlen, Verzweigungslogik, Berechnungen, usw.)\"].apply(lambda x: x.split(',')[0]) \n",
    "    # Descriptives (not in data)\n",
    "    desc_columns = list(codebook[codebook.type.str.contains('descriptive')].variable)\n",
    "    # Datetime\n",
    "    dt_columns = codebook[(codebook.type.isin(['text (datetime_dmy)','text (date_dmy)']))].variable\n",
    "    dt_columns = list(set(data.columns).intersection(dt_columns))\n",
    "    # Numerical\n",
    "    num_columns = []\n",
    "    num_columns += list(codebook[codebook.type.str.contains('calc')].variable)\n",
    "    num_columns += list(codebook[codebook.type.str.contains('checkbox')].variable)\n",
    "    num_columns += list(codebook[codebook.type.str.contains('radio')].variable)\n",
    "    num_columns += list(codebook[codebook.type.str.contains('text \\(number')].variable)\n",
    "    num_columns += list(codebook[codebook.type.str.contains('yesno')].variable)\n",
    "    num_columns += list(codebook[codebook.type.str.contains('dropdown')].variable)\n",
    "    num_columns += list(codebook[codebook.type.str.contains('slider')].variable)\n",
    "    num_columns = list(set(data.columns).intersection(num_columns))\n",
    "    # Text\n",
    "    text_columns = []\n",
    "    text_columns += list(codebook[(codebook.type.str.contains('text')) & (~codebook.type.str.contains('date_dmy|datetime_dmy'))].variable)\n",
    "    text_columns += list(codebook[(codebook.type.str.contains('notes'))].variable)\n",
    "    text_columns += list(codebook[(codebook.type.str.contains('file'))].variable)\n",
    "    text_columns = list(set(data.columns).intersection(text_columns))\n",
    "    assert len(set(num_columns).intersection(set(dt_columns)))==0, set(num_columns).intersection(set(dt_columns))\n",
    "    assert len(set(text_columns).intersection(set(dt_columns)))==0, set(text_columns).intersection(set(dt_columns))\n",
    "    \n",
    "    for c in num_columns:\n",
    "        data[c].replace(\"A 'MySQL server has gone away' error was detected.  It is possible that there was an actual database issue, but it is more likely that REDCap detected this request as a duplicate and killed it.\", np.nan, inplace = True)\n",
    "        data[c] = data[c].astype(float)\n",
    "    data[text_columns] = data[text_columns].astype(str).replace('nan',np.nan)\n",
    "    \n",
    "    for c in dt_columns:\n",
    "        data[c] = pd.to_datetime(data[c])\n",
    "    return data\n",
    "\n",
    "\n",
    "#export\n",
    "@get_efficiently\n",
    "def get_ba_data():\n",
    "    '''This function reads in baseline data from redcap, filters out pilot data, and creates movisens IDs.'''\n",
    "    df = pd.read_csv(os.path.join(get_raw(),\"ba.csv\"))\n",
    "    df['center'] = df.groupby('participant_id').bx_center.transform(lambda x: x.ffill().bfill())\n",
    "    df['center'] = df.center.replace({1:'b',2:'d',3:'m'})\n",
    "    # Creating new movisense IDs (adding center prefix to movisense IDs)\n",
    "    for old_id in ['bx_movisens','bx_movisens_old','bx_movisens_old_2']:\n",
    "        new_id = old_id.replace('bx_','').replace('movisens','mov_id')\n",
    "        df[new_id] = df.groupby('participant_id')[old_id].transform(lambda x: x.ffill().bfill())\n",
    "        df[new_id] = df.center + df[new_id].astype('str').str.strip('0').str.strip('.').apply(lambda x: x.zfill(3))\n",
    "        df[new_id].fillna('nan',inplace = True)\n",
    "        df.loc[df[new_id].str.contains('nan'),new_id] = np.nan\n",
    "    # Removing test participants \n",
    "    remove = ['050744', 'hdfghadgfh', 'LindaEngel', 'test', 'Test001', 'Test001a', 'test0011', 'test0012', 'test0013', 'test0014', 'test0015', 'test002', 'test00229', 'test007', 'test01', 'test012', 'test013', 'test1', 'test2', 'test4', 'test12', 'test999', 'test2021', 'test345345', 'testneu', 'testtest', 'test_0720', 'test_10', 'test_GA', 'Test_JH','test0016','891752080', 'pipingTest', 'test0001', 'test00012', 'test0012a', 'test0015a', 'test0017', 'test10', 'test20212', 'testJohn01', 'test_00213', 'test_00233', 'test_00271', 'test_003', 'test_004', 'test_11_26', 'Test_MS']\n",
    "    df = df[~df.participant_id.astype(str).isin(remove)]\n",
    "    # Checking participant ids (to find new test participants)\n",
    "    bad_ids = df[~df.participant_id.apply(check_participant_id)].participant_id.unique()\n",
    "    assert len(bad_ids)==0, \"Bad participant IDs (should be added to remove): %s\"%', '.join([\"'%s'\"%b for b in bad_ids])\n",
    "    # labeling B07 participant\n",
    "    b07_pps = pd.read_excel(os.path.join(get_external(), 'b7_participants.xlsx'))['Participant ID'].astype(str)\n",
    "    df['is_b07'] = False\n",
    "    df.loc[df.participant_id.isin(b07_pps),'is_b07'] = True\n",
    "    # Setting dtypes based on codebook\n",
    "    df = set_dtypes(df, get_ba_codebook())\n",
    "    # Creating convenience variables\n",
    "    df['is_female'] = df.screen_gender.replace({1:True,2:False})\n",
    "    # Filling in missings from baseline\n",
    "    df['is_female'].fillna(df.bx_sozio_gender.replace({1:False,2:True}), inplace = True)\n",
    "    df['is_female'] = df.groupby('participant_id')['is_female'].transform(lambda x: x.ffill().bfill())\n",
    "    return df\n",
    "\n",
    "#export\n",
    "def get_duplicate_mov_ids():\n",
    "    '''This function creates a dictionary mapping old to new movisens IDs.'''\n",
    "    df = get_ba_data()\n",
    "    replace_dict_1 = dict(zip(df.mov_id_old, df.mov_id))\n",
    "    replace_dict_2 = dict(zip(df.mov_id_old_2, df.mov_id))\n",
    "    replace_dict = {**replace_dict_1, **replace_dict_2}\n",
    "    try:\n",
    "        del replace_dict[np.nan]\n",
    "    except:\n",
    "        pass\n",
    "    return replace_dict\n",
    "\n",
    "assert 'bx_date' in get_ba_data().columns, \"Basic assessment data did not load correctly\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4555c3-5739-48fb-a571-2f739d36e22c",
   "metadata": {},
   "source": [
    "### Getting Movisense data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d8ec1e-b62c-432a-a6e4-01f48fec8a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@get_efficiently\n",
    "def get_mov_data():\n",
    "    \"\"\"\n",
    "    This function gets Movisense data\n",
    "    1) We create unique participnat IDs (e.g. \"b001\"; this is necessary as sites use overapping IDs)\n",
    "    2) We merge double IDs, so participants with two IDs only have one (for this duplicate_ids.csv has to be updated)\n",
    "    3) We remove pilot participants\n",
    "    4) We get starting dates (from the participant overviews in movisense; downloaded as html)\n",
    "    5) We calculate sampling days and end dates based on the starting dates\n",
    "    \"\"\"\n",
    "    # Loading raw data\n",
    "    mov_berlin = pd.read_csv(os.path.join(get_raw(), \"mov_data_b.csv\"), sep = ';')\n",
    "    mov_dresden = pd.read_csv(os.path.join(get_raw(), \"mov_data_d.csv\"), sep = ';')\n",
    "    mov_mannheim = pd.read_csv(os.path.join(get_raw(), \"mov_data_m.csv\"), sep = ';')\n",
    "        \n",
    "    # Merging (participant numbers repeat so we add the first letter of location)\n",
    "    mov_berlin['location'] = 'berlin'\n",
    "    mov_dresden['location'] = 'dresden'\n",
    "    mov_mannheim['location'] = 'mannheim'\n",
    "    df = pd.concat([mov_berlin,mov_dresden,mov_mannheim])\n",
    "    df['participant'] =  df['location'].str[0] + df.Participant.apply(lambda x: '%03d'%int(x))\n",
    "    df['trigger_date'] = pd.to_datetime(df.Trigger_date + ' ' + df.Trigger_time)\n",
    "    \n",
    "    # Merging double IDs (for participants with several movisense IDs)\n",
    "    df['participant'] = df.participant.replace(get_duplicate_mov_ids())\n",
    "    \n",
    "    # Removing pilot participants\n",
    "    df = df[~df.Participant.astype(str).str.contains('test')]\n",
    "    df = df[~df.participant.isin(['m157'])]\n",
    "    \n",
    "    # Adding starting dates to get sampling days\n",
    "    def get_starting_dates(path, pp_prefix = ''):\n",
    "        soup = bs(open(path).read())\n",
    "        ids = [int(x.text) for x in soup.find_all(\"td\", class_ = 'simpleId')]\n",
    "        c_dates = [x.find_all(\"span\")[0]['title'] for x in soup.find_all(\"td\", class_ = 'coupleDate')]\n",
    "        s_dates = [x['value'] for x in soup.find_all(\"input\", class_ = 'dp startDate')]\n",
    "        df = pd.DataFrame({'participant':ids,'coupling_date':c_dates,'starting_date':s_dates})\n",
    "        df['coupling_date'] = pd.to_datetime(df.coupling_date)\n",
    "        df['starting_date'] = pd.to_datetime(df.starting_date)\n",
    "        df.starting_date.fillna(df.coupling_date,inplace = True)\n",
    "        df['participant'] = pp_prefix + df.participant.apply(lambda x: '%03d'%int(x))\n",
    "        return df\n",
    "    \n",
    "    starting_dates = pd.concat([\n",
    "    get_starting_dates(os.path.join(get_raw(), \"starting_dates_b.html\"), 'b'),\n",
    "    get_starting_dates(os.path.join(get_raw(), \"starting_dates_d.html\"), 'd'),\n",
    "    get_starting_dates(os.path.join(get_raw(), \"starting_dates_m.html\"), 'm')\n",
    "    ])\n",
    "    # For participants with several movisense IDs we use the first coupling date\n",
    "    starting_dates.participant.replace(get_duplicate_mov_ids(), inplace = True)\n",
    "    starting_dates = starting_dates.groupby('participant')[['starting_date','coupling_date']].min().reset_index()\n",
    "    df = df.merge(starting_dates, on=\"participant\", how = 'left', indicator = True)\n",
    "    # Checking if starting dates were downloaded\n",
    "    if \"left_only\" in df._merge.unique():\n",
    "        no_starting_dates = df.query('_merge == \"left_only\"').participant.unique()\n",
    "        print(\"Starting dates missing for participants below.  Did you download the participant overviews as html?\", no_starting_dates)\n",
    "    # Calculating movisense sampling day, adding date and end_date\n",
    "    df['sampling_day'] = (df['trigger_date'] - df['starting_date']).dt.days + 1\n",
    "    df['date'] = df.trigger_date.dt.date\n",
    "    df['end_date'] = df.date + pd.DateOffset(days = 365)\n",
    "    df.index.rename('mov_index',inplace = True)\n",
    "    return df\n",
    "\n",
    "assert 'starting_date' in get_mov_data().columns, \"Movisense data did not load correctly\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84042155-2a65-4c4a-8f03-89f0cb6f364c",
   "metadata": {},
   "source": [
    "#### Structure of movisense data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bead81b8-c61a-47d8-a9a3-1dcf9381696e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participant</th>\n",
       "      <th>participant</th>\n",
       "      <th>starting_date</th>\n",
       "      <th>Trigger</th>\n",
       "      <th>Trigger_date</th>\n",
       "      <th>Trigger_counter</th>\n",
       "      <th>Form</th>\n",
       "      <th>INT_Coverage_kleinesBier</th>\n",
       "      <th>INT_Coverage_kleinerWeisswein</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mov_index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>b001</td>\n",
       "      <td>2020-02-24</td>\n",
       "      <td>Button Pressed: Spiele starten und Initialfrag...</td>\n",
       "      <td>2020-02-24</td>\n",
       "      <td>9</td>\n",
       "      <td>Tag 1 Info</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>b001</td>\n",
       "      <td>2020-02-24</td>\n",
       "      <td>Fixed Time: 09:00</td>\n",
       "      <td>2020-02-24</td>\n",
       "      <td>11</td>\n",
       "      <td>Missing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>b001</td>\n",
       "      <td>2020-02-24</td>\n",
       "      <td>Fixed Time: 12:00</td>\n",
       "      <td>2020-02-24</td>\n",
       "      <td>17</td>\n",
       "      <td>Coverage</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>b001</td>\n",
       "      <td>2020-02-24</td>\n",
       "      <td>Fixed Time: 12:00</td>\n",
       "      <td>2020-02-24</td>\n",
       "      <td>17</td>\n",
       "      <td>Craving</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>b001</td>\n",
       "      <td>2020-02-24</td>\n",
       "      <td>Fixed Time: 12:00</td>\n",
       "      <td>2020-02-24</td>\n",
       "      <td>17</td>\n",
       "      <td>MDBF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200176</th>\n",
       "      <td>235</td>\n",
       "      <td>m235</td>\n",
       "      <td>2021-08-16</td>\n",
       "      <td>Button Pressed: Spiele starten und Initialfrag...</td>\n",
       "      <td>2021-08-16</td>\n",
       "      <td>16</td>\n",
       "      <td>Tag 1 Info</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200177</th>\n",
       "      <td>235</td>\n",
       "      <td>m235</td>\n",
       "      <td>2021-08-16</td>\n",
       "      <td>Button Pressed: Spiele starten und Initialfrag...</td>\n",
       "      <td>2021-08-16</td>\n",
       "      <td>16</td>\n",
       "      <td>Initial</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200178</th>\n",
       "      <td>235</td>\n",
       "      <td>m235</td>\n",
       "      <td>2021-08-16</td>\n",
       "      <td>Button Pressed: Spiele starten und Initialfrag...</td>\n",
       "      <td>2021-08-16</td>\n",
       "      <td>16</td>\n",
       "      <td>GBE_Tag1_Vorher</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200179</th>\n",
       "      <td>235</td>\n",
       "      <td>m235</td>\n",
       "      <td>2021-08-16</td>\n",
       "      <td>Button Pressed: Spiele starten und Initialfrag...</td>\n",
       "      <td>2021-08-16</td>\n",
       "      <td>16</td>\n",
       "      <td>GreatBrainExperiment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200180</th>\n",
       "      <td>235</td>\n",
       "      <td>m235</td>\n",
       "      <td>2021-08-16</td>\n",
       "      <td>Button Pressed: Spiele starten und Initialfrag...</td>\n",
       "      <td>2021-08-16</td>\n",
       "      <td>16</td>\n",
       "      <td>GreatBrainExperiment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200181 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Participant participant starting_date  \\\n",
       "mov_index                                          \n",
       "0                    1        b001    2020-02-24   \n",
       "1                    1        b001    2020-02-24   \n",
       "2                    1        b001    2020-02-24   \n",
       "3                    1        b001    2020-02-24   \n",
       "4                    1        b001    2020-02-24   \n",
       "...                ...         ...           ...   \n",
       "200176             235        m235    2021-08-16   \n",
       "200177             235        m235    2021-08-16   \n",
       "200178             235        m235    2021-08-16   \n",
       "200179             235        m235    2021-08-16   \n",
       "200180             235        m235    2021-08-16   \n",
       "\n",
       "                                                     Trigger Trigger_date  \\\n",
       "mov_index                                                                   \n",
       "0          Button Pressed: Spiele starten und Initialfrag...   2020-02-24   \n",
       "1                                          Fixed Time: 09:00   2020-02-24   \n",
       "2                                          Fixed Time: 12:00   2020-02-24   \n",
       "3                                          Fixed Time: 12:00   2020-02-24   \n",
       "4                                          Fixed Time: 12:00   2020-02-24   \n",
       "...                                                      ...          ...   \n",
       "200176     Button Pressed: Spiele starten und Initialfrag...   2021-08-16   \n",
       "200177     Button Pressed: Spiele starten und Initialfrag...   2021-08-16   \n",
       "200178     Button Pressed: Spiele starten und Initialfrag...   2021-08-16   \n",
       "200179     Button Pressed: Spiele starten und Initialfrag...   2021-08-16   \n",
       "200180     Button Pressed: Spiele starten und Initialfrag...   2021-08-16   \n",
       "\n",
       "           Trigger_counter                  Form  INT_Coverage_kleinesBier  \\\n",
       "mov_index                                                                    \n",
       "0                        9            Tag 1 Info                       NaN   \n",
       "1                       11               Missing                       NaN   \n",
       "2                       17              Coverage                       NaN   \n",
       "3                       17               Craving                       NaN   \n",
       "4                       17                  MDBF                       NaN   \n",
       "...                    ...                   ...                       ...   \n",
       "200176                  16            Tag 1 Info                       NaN   \n",
       "200177                  16               Initial                       NaN   \n",
       "200178                  16       GBE_Tag1_Vorher                       NaN   \n",
       "200179                  16  GreatBrainExperiment                       NaN   \n",
       "200180                  16  GreatBrainExperiment                       NaN   \n",
       "\n",
       "           INT_Coverage_kleinerWeisswein  \n",
       "mov_index                                 \n",
       "0                                    NaN  \n",
       "1                                    NaN  \n",
       "2                                    NaN  \n",
       "3                                    NaN  \n",
       "4                                    NaN  \n",
       "...                                  ...  \n",
       "200176                               NaN  \n",
       "200177                               NaN  \n",
       "200178                               NaN  \n",
       "200179                               NaN  \n",
       "200180                               NaN  \n",
       "\n",
       "[200181 rows x 9 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_mov_data()[['Participant','participant','starting_date','Trigger','Trigger_date','Trigger_counter','Form','INT_Coverage_kleinesBier','INT_Coverage_kleinerWeisswein']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e879a497-d136-47b9-9e9e-f0e6cdc32784",
   "metadata": {},
   "source": [
    "### Getting two-day data\n",
    "This is a subset of the movisense data (only the two-daily questions), which we reformat so that each day is one one line.  We also add nan data for dates after the last data was received until 365 days until the starting date.  We rearrange answers to retrospective questions, so they are associated with the date in question rather than the date on which the question was answered.  For example, the answer to the question \"How many beers did you drink two days ago\" gets shifted two days back from the date of the question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29cf8fc8-19ef-4a19-8995-da79547a61ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_alcohol_per_drink():\n",
    "    path = os.path.join(get_external(),'alcohol_per_drink.csv')\n",
    "    if not os.path.isfile(path):\n",
    "        return None\n",
    "    else:\n",
    "        return pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9773301-5f61-4758-a783-0e09e5539e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert type(get_alcohol_per_drink()) == type(pd.DataFrame()), \"Could not load 'alcohol_per_drink.csv' from external data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2824683-9fa8-4ce7-803b-e82907a4493d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@get_efficiently\n",
    "def get_two_day_data():\n",
    "    \"\"\"Gets two-day which are a subset of mov_data\n",
    "    1) We select two-day forms and turn the dataframe into one row per participant-date (Form repetitions on the same day are removed)\n",
    "    2) We reduce all drinking questions to an easily readable dictionary of drink amounts.\n",
    "    3) We add missing data for dates on which we did not receive answers (starting 2 days before starting date up to 365 days after)\n",
    "    4) We shift answers from retrospective drinking questions backwards to the adequate date (e.g. one day back for yesterday questions) \n",
    "    \"\"\"\n",
    "    mov_data = get_mov_data().reset_index()\n",
    "    drinking_columns = [c for c in mov_data.columns if c.startswith(\"Anzahl\") and \"10day\" not in c]\n",
    "    mdbf_columns = [c for c in mov_data.columns if \"MDBF\" in c and \"INT\" not in c]\n",
    "    two_day_columns = ['mov_index','starting_date','end_date','sampling_day'] + drinking_columns + mdbf_columns + ['soziale_isolation','alternative_rewards','craving','Limit','Kontrolle']\n",
    "    # 1) Turning df into one line per date\n",
    "    two_day_forms = [\"Coverage\",\"Soziale Isolation\",\"Craving\",\"MDBF\",\"Alternative Rewards\",\"Limits & Control\"]\n",
    "    df = mov_data.sort_values(by=['participant','trigger_date','Form','Trigger_counter'])\n",
    "    df = df[df.Form.isin(two_day_forms)].groupby([\"participant\",\"date\"])[two_day_columns].first().dropna(how='all').reset_index()\n",
    "    # 2) Turning drinking answers into dictionaries\n",
    "    df[drinking_columns].fillna(0,inplace = True)\n",
    "    df['drinks_gestern'] = df[[c for c in drinking_columns if \"vorgestern\" not in c]].fillna(0).agg(lambda x: x.to_dict(), axis=1)\n",
    "    df['drinks_vorgestern'] = df[[c for c in drinking_columns if \"vorgestern\" in c]].fillna(0).agg(lambda x: x.to_dict(), axis=1)\n",
    "    # Adding missing values\n",
    "    def add_missing_data(df):\n",
    "        dates = pd.date_range(df.starting_date.iloc[0]-pd.DateOffset(days = 2), df.end_date.iloc[0])\n",
    "        df = df.reindex(dates)\n",
    "        df.index.names = ['date']\n",
    "        df[['starting_date','sampling_day']] = df[['starting_date','sampling_day']].bfill().ffill()\n",
    "        return df\n",
    "    df = df.set_index('date').groupby('participant').apply(add_missing_data).drop(columns='participant').reset_index()\n",
    "    \n",
    "    # 3) Shifting back retrospective answers\n",
    "    df['drinks'] = df['drinks_gestern'].shift(-1) # Drinks yesterday get shifted back one day\n",
    "    df['drinks'].fillna(df['drinks_vorgestern'].shift(-2), inplace = True) # Drinks before yesterday shift back two days\n",
    "    df['limit'] = df.Limit.ffill(limit=8) # Limit gets repeated forward for eight days\n",
    "    df['control'] = df.Kontrolle.bfill(limit=8) # Control is repeated backward for eight days\n",
    "    # 4) Calculating daily alcohol consumption in grams\n",
    "    alc_dict = {\"Anzahl\"+k:v for k,v in get_alcohol_per_drink().set_index('drink')['ml_alc_per_drink'].to_dict().items()}\n",
    "    def calculate_g_alc(x):\n",
    "        if x != x:\n",
    "            ml_alc = np.nan\n",
    "        else:\n",
    "            ml_alc = 0\n",
    "            for k,v in x.items():\n",
    "                if v > 0:\n",
    "                    ml_alc += alc_dict[k.split('_')[0]] * v\n",
    "        return ml_alc * .8\n",
    "    df['g_alc']  = df.drinks.apply(calculate_g_alc)\n",
    "    # Returning relevant columns only\n",
    "    df = df.reset_index()\n",
    "    df['sampling_day'] = df.groupby('participant').starting_date.cumcount() + 1\n",
    "    df.index.rename('two_day_index',inplace = True)\n",
    "    return df[['mov_index','participant','starting_date','date','sampling_day'] + mdbf_columns + ['soziale_isolation','alternative_rewards','craving','limit','control','drinks','g_alc']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89993eaf-aa86-4b25-9d87-b1a63d5cacca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_one_line_per_participant_day():\n",
    "    return get_two_day_data().groupby(['participant','date']).date.count().value_counts().index[0] == 1\n",
    "\n",
    "assert test_one_line_per_participant_day(), \"Two day data does not have one line per participant day.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c63c32-af1a-48f1-b0be-a94f62793e2c",
   "metadata": {},
   "source": [
    "#### Structure of two-day data\n",
    "> Warning: Note that sampling days run further than 365.  This should not be the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1782c327-cd94-4f14-a760-aab316661347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing two_day_data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mov_index</th>\n",
       "      <th>participant</th>\n",
       "      <th>date</th>\n",
       "      <th>starting_date</th>\n",
       "      <th>sampling_day</th>\n",
       "      <th>soziale_isolation</th>\n",
       "      <th>drinks</th>\n",
       "      <th>g_alc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>two_day_index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>b001</td>\n",
       "      <td>2020-02-22</td>\n",
       "      <td>2020-02-24</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'AnzahlKleinesBier_vorgestern': 0.0, 'AnzahlM...</td>\n",
       "      <td>6.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>b001</td>\n",
       "      <td>2020-02-23</td>\n",
       "      <td>2020-02-24</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'AnzahlKleinesBier': 0.0, 'AnzahlMittlereBier...</td>\n",
       "      <td>35.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.0</td>\n",
       "      <td>b001</td>\n",
       "      <td>2020-02-24</td>\n",
       "      <td>2020-02-24</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>b001</td>\n",
       "      <td>2020-02-25</td>\n",
       "      <td>2020-02-24</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>b001</td>\n",
       "      <td>2020-02-26</td>\n",
       "      <td>2020-02-24</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139779</th>\n",
       "      <td>NaN</td>\n",
       "      <td>m234</td>\n",
       "      <td>2022-08-12</td>\n",
       "      <td>2021-08-16</td>\n",
       "      <td>364</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139780</th>\n",
       "      <td>NaN</td>\n",
       "      <td>m234</td>\n",
       "      <td>2022-08-13</td>\n",
       "      <td>2021-08-16</td>\n",
       "      <td>365</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139781</th>\n",
       "      <td>NaN</td>\n",
       "      <td>m234</td>\n",
       "      <td>2022-08-14</td>\n",
       "      <td>2021-08-16</td>\n",
       "      <td>366</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139782</th>\n",
       "      <td>NaN</td>\n",
       "      <td>m234</td>\n",
       "      <td>2022-08-15</td>\n",
       "      <td>2021-08-16</td>\n",
       "      <td>367</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139783</th>\n",
       "      <td>NaN</td>\n",
       "      <td>m234</td>\n",
       "      <td>2022-08-16</td>\n",
       "      <td>2021-08-16</td>\n",
       "      <td>368</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>139784 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               mov_index participant       date starting_date  sampling_day  \\\n",
       "two_day_index                                                                 \n",
       "0                    NaN        b001 2020-02-22    2020-02-24             1   \n",
       "1                    NaN        b001 2020-02-23    2020-02-24             2   \n",
       "2                    6.0        b001 2020-02-24    2020-02-24             3   \n",
       "3                    NaN        b001 2020-02-25    2020-02-24             4   \n",
       "4                    NaN        b001 2020-02-26    2020-02-24             5   \n",
       "...                  ...         ...        ...           ...           ...   \n",
       "139779               NaN        m234 2022-08-12    2021-08-16           364   \n",
       "139780               NaN        m234 2022-08-13    2021-08-16           365   \n",
       "139781               NaN        m234 2022-08-14    2021-08-16           366   \n",
       "139782               NaN        m234 2022-08-15    2021-08-16           367   \n",
       "139783               NaN        m234 2022-08-16    2021-08-16           368   \n",
       "\n",
       "               soziale_isolation  \\\n",
       "two_day_index                      \n",
       "0                            NaN   \n",
       "1                            NaN   \n",
       "2                            1.0   \n",
       "3                            NaN   \n",
       "4                            NaN   \n",
       "...                          ...   \n",
       "139779                       NaN   \n",
       "139780                       NaN   \n",
       "139781                       NaN   \n",
       "139782                       NaN   \n",
       "139783                       NaN   \n",
       "\n",
       "                                                          drinks  g_alc  \n",
       "two_day_index                                                            \n",
       "0              {'AnzahlKleinesBier_vorgestern': 0.0, 'AnzahlM...    6.4  \n",
       "1              {'AnzahlKleinesBier': 0.0, 'AnzahlMittlereBier...   35.2  \n",
       "2                                                            NaN    NaN  \n",
       "3                                                            NaN    NaN  \n",
       "4                                                            NaN    NaN  \n",
       "...                                                          ...    ...  \n",
       "139779                                                       NaN    NaN  \n",
       "139780                                                       NaN    NaN  \n",
       "139781                                                       NaN    NaN  \n",
       "139782                                                       NaN    NaN  \n",
       "139783                                                       NaN    NaN  \n",
       "\n",
       "[139784 rows x 8 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_two_day_data(update = True)[['mov_index','participant','date','starting_date','sampling_day','soziale_isolation','drinks','g_alc']]#.iloc[:20]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
