{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c976499f-e466-4ddf-a983-f1bca64e3b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp gbe.baseline_drinking.separate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dcc5595-56ec-411f-9fec-cff0e01d3bfc",
   "metadata": {},
   "source": [
    "# Factor analysis\n",
    "Factor analyses require large sample sizes, which this study is perfect for."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c46b07-f11b-4ad6-908e-a73c84741012",
   "metadata": {},
   "source": [
    "> Note: Next step is to get the scoring data per session so tasks is a session-based df. Then this df is averaged before the factor analysis, but session-level scores are used to generate factor scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90bd9e47-d86a-426e-90ee-fe9243ce2372",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ab1e1e-ded1-4c3e-bb03-24ccbd83c6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%reload_ext rpy2.ipython\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "custom_params = {\"axes.spines.right\": False, \"axes.spines.top\": False}\n",
    "sns.set_theme(style=\"white\", font_scale = 1.3, rc=custom_params)\n",
    "from IPython.core.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439b0844-2e9e-4671-93e7-f2550eb8c53d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from trr265.gbe.ist.data_provider import ISTDataProvider\n",
    "from trr265.gbe.wm.data_provider import WMDataProvider\n",
    "from trr265.gbe.sst.data_provider import SSTDataProvider\n",
    "from trr265.gbe.rtt.data_provider import RTTDataProvider\n",
    "\n",
    "import trr265.gbe.ist.scoring as ist_scoring \n",
    "import trr265.gbe.wm.scoring as wm_scoring \n",
    "import trr265.gbe.sst.scoring as sst_scoring \n",
    "import trr265.gbe.rtt.scoring as rtt_scoring \n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ad245e-a268-4bbe-8df8-288198e7cf53",
   "metadata": {},
   "source": [
    "## Loading the data\n",
    "In this notebook, all tests and examples are run on the initial baseline dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd6efb3-c6eb-47ed-9a73-343c312522e3",
   "metadata": {},
   "source": [
    "### Information sampling task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d0ed23-d45f-46cf-945a-35861de5c5e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Lade nötiges Paket: lme4\n",
      "\n",
      "R[write to console]: Lade nötiges Paket: Matrix\n",
      "\n",
      "R[write to console]: \n",
      "Attache Paket: ‘lmerTest’\n",
      "\n",
      "\n",
      "R[write to console]: Das folgende Objekt ist maskiert ‘package:lme4’:\n",
      "\n",
      "    lmer\n",
      "\n",
      "\n",
      "R[write to console]: Das folgende Objekt ist maskiert ‘package:stats’:\n",
      "\n",
      "    step\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Length mismatch: Expected axis has 2 elements, new values have 1 elements",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/16/2wxbnpk5321f8g40bxf0ht_h0000gn/T/ipykernel_70633/310315181.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_gbe_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'participant'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_on\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'gbe_index'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'left'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m#ist = ist.groupby('participant').mean()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'ist_oversampling'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/miniconda3/envs/trr265/lib/python3.9/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   5498\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5499\u001b[0m             \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5500\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5501\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5502\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/trr265/lib/python3.9/site-packages/pandas/_libs/properties.pyx\u001b[0m in \u001b[0;36mpandas._libs.properties.AxisProperty.__set__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/trr265/lib/python3.9/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_set_axis\u001b[0;34m(self, axis, labels)\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 766\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    767\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/trr265/lib/python3.9/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mset_axis\u001b[0;34m(self, axis, new_labels)\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_labels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;31m# Caller is responsible for ensuring we have an Index object.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_set_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/trr265/lib/python3.9/site-packages/pandas/core/internals/base.py\u001b[0m in \u001b[0;36m_validate_set_axis\u001b[0;34m(self, axis, new_labels)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mnew_len\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mold_len\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m     58\u001b[0m                 \u001b[0;34mf\"Length mismatch: Expected axis has {old_len} elements, new \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                 \u001b[0;34mf\"values have {new_len} elements\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Length mismatch: Expected axis has 2 elements, new values have 1 elements"
     ]
    }
   ],
   "source": [
    "# Getting raw data\n",
    "dp = ISTDataProvider('/Users/hilmarzech/Projects/trr265/trr265/data/')\n",
    "df = dp.get_ist_data()\n",
    "# Adding data from redcap\n",
    "df = df.merge(dp.get_gbe_data(columns = ['participant','session_number','is_initial','is_baseline']), left_on = 'gbe_index', right_index = True, how = 'left')\n",
    "# Filtering out replication and ema data\n",
    "#df = df.query(\"is_initial and is_baseline\")\n",
    "df = df.query(\"is_baseline == True\")\n",
    "ist = ist_scoring.get_oversampling_predicted_joint(df)[0]\n",
    "ist = ist.merge(dp.get_gbe_data(columns = ['participant']), left_on = 'gbe_index', right_index = True, how = 'left')\n",
    "#ist = ist.groupby('participant').mean()\n",
    "ist.columns = ['ist_oversampling']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38ccab1-9025-4706-81ca-8e13161a52cd",
   "metadata": {},
   "source": [
    "### Working memory task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56a5135-8598-4f6d-9758-0930601df18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting raw data\n",
    "dp = WMDataProvider('/Users/hilmarzech/Projects/trr265/trr265/data/')\n",
    "df = dp.get_wm_data()\n",
    "# Adding data from redcap\n",
    "df = df.merge(dp.get_gbe_data(columns = ['participant','session_number','is_initial','is_baseline']), left_on = 'gbe_index', right_index = True, how = 'left')\n",
    "# Filtering out replication and ema data\n",
    "#df = df.query(\"is_initial and is_baseline\")\n",
    "df = df.query(\"is_baseline == True\")\n",
    "\n",
    "# Filtering participants with old app\n",
    "df = dp.filter_old_app_sessions(df)\n",
    "df = dp.filter_level_two_failures(df)\n",
    "wm = wm_scoring.get_perc_correct_predicted_sep_trial(df)[0]\n",
    "wm = wm.merge(dp.get_gbe_data(columns = ['participant']), left_on = 'gbe_index', right_index = True, how = 'left')\n",
    "#wm = wm.groupby('participant').mean()\n",
    "wm = wm.rename(columns={'perc_predicted_sep_trial_no_distractor_1': 'wm_no_1',\n",
    "                       'perc_predicted_sep_trial_no_distractor_2': 'wm_no_2',\n",
    "                       'perc_predicted_sep_trial_encoding_distractor': 'wm_encoding',\n",
    "                       'perc_predicted_sep_trial_delayed_distractor':'wm_delayed'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b20533d-bcd7-4e7c-ae66-f7adfcbdeb0d",
   "metadata": {},
   "source": [
    "### Risk taking task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9840fe-d833-4610-847d-c7740d79957a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting raw data\n",
    "dp = RTTDataProvider('/Users/hilmarzech/Projects/trr265/trr265/data/')\n",
    "df = dp.get_rtt_data()\n",
    "# Adding data from redcap\n",
    "df = df.merge(dp.get_gbe_data(columns = ['participant','session_number','is_initial','is_baseline']), left_on = 'gbe_index', right_index = True, how = 'left')\n",
    "# Filtering out replication and ema data\n",
    "#df = df.query(\"is_initial and is_baseline\")\n",
    "df = df.query(\"is_baseline == True\")\n",
    "\n",
    "rtt = rtt_scoring.get_perc_gamble_predicted_joint(df)[0]\n",
    "rtt = rtt.merge(dp.get_gbe_data(columns = ['participant']), left_on = 'gbe_index', right_index = True, how = 'left')\n",
    "#rtt = rtt.groupby('participant').mean()\n",
    "rtt = rtt.rename(columns={'perc_gamble_joint_win': 'rtt_win',\n",
    "                       'perc_gamble_joint_loss': 'rtt_loss',\n",
    "                       'perc_gamble_joint_mixed': 'rtt_mixed'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6ac746-2053-497f-8aa9-6caaf5e1901c",
   "metadata": {},
   "source": [
    "### Stop signal task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e80151-63d5-42fb-87f3-a3ec4b73dfdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting raw data\n",
    "dp = SSTDataProvider('/Users/hilmarzech/Projects/trr265/trr265/data/')\n",
    "df = dp.get_sst_data()\n",
    "# Adding data from redcap\n",
    "df = df.merge(dp.get_gbe_data(columns = ['participant','session_number','is_initial','is_baseline']), left_on = 'gbe_index', right_index = True, how = 'left')\n",
    "# Filtering out replication and ema data\n",
    "#df = df.query(\"is_initial and is_baseline\")\n",
    "df = df.query(\"is_baseline == True\")\n",
    "\n",
    "sst = sst_scoring.get_ssrt_predicted_joint(df)[0]\n",
    "sst = sst.merge(dp.get_gbe_data(columns = ['participant']), left_on = 'gbe_index', right_index = True, how = 'left')\n",
    "#sst = sst.groupby('participant').mean()\n",
    "sst.columns = ['ssrt']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed9847e-1693-4bd2-8763-0716f40431e4",
   "metadata": {},
   "source": [
    "## Factor analysis\n",
    "Using oblimin rotation similar to Eisenberg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24bdb69-74ab-4d4c-8385-113b9695dcbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from factor_analyzer.factor_analyzer import calculate_kmo # The factor_analyzer package is based on the R psych package\n",
    "from factor_analyzer.factor_analyzer import calculate_bartlett_sphericity\n",
    "from factor_analyzer import FactorAnalyzer\n",
    "\n",
    "from scipy.spatial.distance import pdist\n",
    "import numpy as np\n",
    "from scipy.cluster.hierarchy import linkage\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "import numpy as np\n",
    "\n",
    "def check_factor_analysis(df):\n",
    "    # Testing suitability for factor analysis\n",
    "    chi_square_value,p_value=calculate_bartlett_sphericity(df)\n",
    "    kmo_all,kmo_model=calculate_kmo(df)\n",
    "    bartletts_passed = \"passes\" if p_value < .05 else \"failed\"\n",
    "    display(HTML(\"Bartlett's test %s: chi_square = %.2f; p = %.2e; Kaiser-Meyer-Olkin test: %.3f (ideally should be above .8).\"%(bartletts_passed, chi_square_value, p_value,kmo_model)))\n",
    "    \n",
    "    \n",
    "def scree_plot(df, rotation = 'oblimin'):\n",
    "    fa = FactorAnalyzer(rotation=rotation)\n",
    "    fa.fit(df)\n",
    "    ev, v = fa.get_eigenvalues()\n",
    "    fig, axes = plt.subplots(1, 1, figsize=(5, 7))\n",
    "    plt.scatter(range(1, df.shape[1]+1),ev)\n",
    "    ax = plt.plot(range(1, df.shape[1]+1),ev)\n",
    "    plt.axhline(1, color = 'black', linestyle = '--')\n",
    "    plt.show()\n",
    "    \n",
    "def factor_analysis(df, n_factors, rotation = 'oblimin'):\n",
    "    fa = FactorAnalyzer(rotation=rotation, n_factors = n_factors)\n",
    "    fa.fit(df)\n",
    "    return fa\n",
    "\n",
    "def get_factor_loadings(fa, df):\n",
    "     return pd.DataFrame(fa.loadings_, columns = [\"Factor %d\"%i for i in range(1, fa.n_factors+1)], index = df.columns)\n",
    "    \n",
    "def dendogram(df, distances = 'euclidean'):\n",
    "    #d = np.transpose(np.arange(1,10001).reshape(100,100))\n",
    "    d = df.values\n",
    "    distances = pdist(d, distances) #euclidean\n",
    "    link = linkage(distances, \"average\")\n",
    "    default_color_threshold = 0.7*np.max(link[:,2])\n",
    "    print(default_color_threshold)\n",
    "    clusters = cutreeHybrid(link, distances, minClusterSize = 3, pamStage = False)\n",
    "    fig, axes = plt.subplots(1, 1, figsize=(5, 2))\n",
    "    axes.spines['left'].set_visible(False)\n",
    "    axes.spines['bottom'].set_visible(False)\n",
    "    plt.xlabel('sample index')\n",
    "    plt.ylabel('distance (Ward)')\n",
    "    dendo = dendrogram(link, labels=df.index, leaf_rotation=90,color_threshold=default_color_threshold, above_threshold_color= 'grey')\n",
    "    plt.show()\n",
    "    return dendo\n",
    "    \n",
    "def factor_loading_heatmap(factor_loadings,column_order):\n",
    "    return sns.heatmap(factor_loadings.T[column_order], annot=True, center = 0, vmin=-1, vmax=1, cmap = sns.color_palette(\"vlag\", as_cmap=True), fmt=\".2f\", annot_kws={'size': 10})\n",
    "\n",
    "\n",
    "            \n",
    "tasks = pd.concat([wm.groupby('participant').mean(), \n",
    "                   -sst.groupby('participant').mean(), \n",
    "                   rtt.groupby('participant').mean(),\n",
    "                   ist.groupby('participant').mean()],axis = 1).dropna() # We reverse the SSTs to align them with other scores \n",
    "check_factor_analysis(tasks)\n",
    "scree_plot(tasks, rotation = 'oblimin')\n",
    "fa = factor_analysis(tasks, 3, rotation = 'oblimin')\n",
    "factor_loadings = get_factor_loadings(fa, tasks)\n",
    "dendo = dendogram(factor_loadings)\n",
    "factor_loading_heatmap(factor_loadings, dendo['ivl'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04233b3f-cf54-4562-a965-0ff6bc549229",
   "metadata": {},
   "source": [
    "### Factor scores\n",
    "Factor scores calculated via the ten Berge method (for oblim rotation; Eisenberg; https://www.sciencedirect.com/science/article/pii/S0024379597100076; https://stackoverflow.com/questions/67856186/correct-way-to-calculate-correlations-between-factors)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1326078-4ea7-4f7c-9f58-70b548d06430",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "def matrix_sqrt(x):\n",
    "    \"\"\"\n",
    "    Compute the square root of the eigen values (eVal),\n",
    "    and then take $eVec * diag(eVals^0.5) * eVec^T$\n",
    "    \"\"\"\n",
    "    evals, evecs = np.linalg.eig(x)\n",
    "    evals[evals < 0] = np.finfo(float).eps\n",
    "    sqrt_evals = np.sqrt(evals)\n",
    "    return evecs.dot(np.diag(sqrt_evals)).dot(evecs.T)\n",
    "\n",
    "\n",
    "def inv_matrix_sqrt(x):\n",
    "    \"\"\"\n",
    "    Compute the inverse square root of the eigen values (eVal),\n",
    "    and then take $eVec * diag(1 / eVals^0.5) * eVec^T$\n",
    "    \"\"\"\n",
    "    evals, evecs = np.linalg.eig(x)\n",
    "    if np.iscomplex(evals).any():\n",
    "        warnings.warn('Complex eigen values detected; results are suspect.')\n",
    "        return x\n",
    "    evals[evals < np.finfo(float).eps] = 100 * np.finfo(float).eps\n",
    "    inv_sqrt_evals =  1 / np.sqrt(evals)\n",
    "    return evecs.dot(np.diag(inv_sqrt_evals)).dot(evecs.T)\n",
    "\n",
    "\n",
    "def ten_berge(X, loadings, phi=None):\n",
    "    \"\"\"\n",
    "    Estimate factor scores using the \"ten Berge\" method.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array-like\n",
    "        The data set\n",
    "    loadings : array-like\n",
    "        The loadings matrix\n",
    "\n",
    "    Reference\n",
    "    ----------\n",
    "    https://www.sciencedirect.com/science/article/pii/S0024379597100076\n",
    "    \"\"\"\n",
    "    # get the number of factors from the loadings\n",
    "    n_factors = loadings.shape[1]\n",
    "    corr = np.corrcoef(X, rowvar=False)\n",
    "    # if `phi` is None, create a diagonal matrix\n",
    "    phi = np.diag(np.ones(n_factors)) if phi is None else phi\n",
    "    # calculate intermediate metrics\n",
    "    load = loadings.dot(matrix_sqrt(phi))\n",
    "    corr_inv = inv_matrix_sqrt(corr)\n",
    "    temp = corr_inv.dot(load)\\\n",
    "                   .dot(inv_matrix_sqrt(load.T.dot(np.linalg.inv(corr))\n",
    "                                              .dot(load)))\n",
    "    # calcualte weights\n",
    "    weights = corr_inv.dot(temp)\\\n",
    "                      .dot(matrix_sqrt(phi))\n",
    "    # calculate scores, given weights\n",
    "    scores = scale(X).dot(weights)\n",
    "    return scores\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/vincentarelbundock/Rdatasets/master/csv/psych/bfi.csv')\n",
    "df = df.filter(regex='^A[1-5]|^N').copy()\n",
    "df = df.fillna(df.median(0))\n",
    "\n",
    "fa2 = FactorAnalyzer(n_factors=5, rotation=None).fit(df)\n",
    "pd.DataFrame(ten_berge(df, fa2.loadings_))#.corr().round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58437a57-2188-46b6-8ed5-b7028c59a4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(ten_berge(tasks, fa.loadings_))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
